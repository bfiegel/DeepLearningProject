{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISE 6380: Chernobyl Blue Chillers - GANdinsky.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHE8cdQMTO1U",
        "outputId": "e28314f0-f7e5-4da6-8210-bebf4854cb80"
      },
      "source": [
        "!pip install biopython\n",
        "\n",
        "import Bio\n",
        "from Bio import SeqIO\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import os\n",
        "import pathlib\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "import urllib.request\n",
        "from zipfile import ZipFile\n",
        "\n",
        "#import shutil\n",
        "#shutil.rmtree('/content/drive')\n",
        "os.chdir(\"/\")\n",
        "os.getcwd()\n",
        "\n",
        "def prep_drive(doMount, dirsToMake):\n",
        "  #mount google drive for longterm storage\n",
        "  if True == doMount:\n",
        "    mountPoint='/content/drive/'\n",
        "    if not os.path.exists(mountPoint):\n",
        "      drive.mount(mountPoint, force_remount=False)\n",
        "\n",
        "  for d in dirsToMake:\n",
        "    if not os.path.isdir(d):\n",
        "      os.makedirs(d)\n",
        "\n",
        "def download_and_extract_file(url, local_bundle_path, extraction_directory='.'):\n",
        "  initial_directory = os.getcwd()\n",
        "  os.chdir(extraction_directory)\n",
        "  try:\n",
        "    if not os.path.exists(local_bundle_path):\n",
        "      # download the dataset\n",
        "      urllib.request.urlretrieve(url,local_bundle_path )\n",
        "      \n",
        "      if local_bundle_path.endswith('.zip'):\n",
        "        # extract the dataset and store it on google drive\n",
        "        with ZipFile(local_bundle_path, 'r') as zip:\n",
        "          zip.extractall()\n",
        "      elif local_bundle_path.endswith('.tar.gz') or local_bundle_path.endswith('.tgz'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:gz\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      elif local_bundle_path.endswith('.tar'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      elif path.endswith('.tar.bz2') or path.endswith('.tbz'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:bz2\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      else: \n",
        "        raise Exception(local_bundle_path + \" has an unrecognized file extension\")\n",
        "  finally:\n",
        "    os.chdir(initial_directory)\n",
        "\n",
        "def noop():\n",
        "  return None\n"
      ],
      "execution_count": 666,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (1.78)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdKiccT1xFUi",
        "outputId": "f537e2f4-b488-4f28-e3c4-7bbea603e453"
      },
      "source": [
        "class DNASamples(object):\n",
        "  def __init__(self, useSampleData, shape=(1,128), projectDir=None):\n",
        "    self.Shape=shape\n",
        "    self.UseSampleData = useSampleData\n",
        "    self.ProjectDir=projectDir\n",
        "    if None == self.ProjectDir:\n",
        "      self.ProjectDir=\"/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/\"\n",
        "      if True == self.UseSampleData:\n",
        "        # If using sample data, overwrite the parameters\n",
        "        self.ProjectDir=\"/content/ChernobylBlueChillers/\"\n",
        "\n",
        "    self.SampleUrl=\"https://drive.google.com/uc?export=download&id=1ZPY_-CFnrCiDucbM0kmQB0G6rgOjoXBs\"\n",
        "    self.SampleDir=self.ProjectDir\n",
        "    self.SampleBundle=self.SampleDir + 'SampleData.zip'\n",
        "\n",
        "    self.ProjectDnaDir=self.ProjectDir + \"DNAData/\"\n",
        "    #Bsubtilis_JRC DNA data\n",
        "    self.BsubtilisJRCBundleUrl=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-JRC.tgz\"\n",
        "    self.BsubtilisJRCBundle = self.ProjectDnaDir + 'Bsubtilis-JRC.tgz'\n",
        "    self.ProjectDnaBsubtilisJRCDir=self.ProjectDnaDir + \"Bsubtilis-JRC/\"\n",
        "    self.ProjectDnaBsubtilisJRCData = [self.ProjectDnaBsubtilisJRCDir + \"Bsubtilis-JRC.fastq\"]\n",
        "\n",
        "    #Bsubtilis_LGL DNA data\n",
        "    self.BsubtilisLGLBundleUrl=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-LGL.tgz\"\n",
        "    self.BsubtilisLGLBundle = self.ProjectDnaDir + 'Bsubtilis-LGL.tgz'\n",
        "    self.ProjectDnaBsubtilisLGLDir=self.ProjectDnaDir + \"Bsubtilis-LGL/\"\n",
        "    self.ProjectDnaBsubtilisLGLData = []#[self.ProjectDnaBsubtilisLGLDir + \"Bsubtilis-LGL.fastq\"]\n",
        "\n",
        "    #Bsubtilis_LHL DNA data\n",
        "    self.BsubtilisLHLBundleUrl=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-LHL.tgz\"\n",
        "    self.BsubtilisLHLBundle = self.ProjectDnaDir + 'Bsubtilis-LHL.tgz'\n",
        "    self.ProjectDnaBsubtilisLHLDir=self.ProjectDnaDir + \"Bsubtilis-LHL/\"\n",
        "    self.ProjectDnaBsubtilisLHLData = [self.ProjectDnaBsubtilisLHLDir + \"Bsubtilis_S1_L001_R1_001.fastq\"]\n",
        "\n",
        "    if True == self.UseSampleData:\n",
        "      # If using sample data, overwrite the parameters\n",
        "      self.ProjectDnaBsubtilisJRCData = [self.ProjectDnaBsubtilisJRCDir + \"Bsubtilis-JRC-truncated.fastq\"]\n",
        "      self.ProjectDnaBsubtilisLHLData = [self.ProjectDnaBsubtilisLHLDir + \"Bsubtilis_S1_L001_R1_001-truncated.fastq\"]\n",
        "\n",
        "    self.DNAData=[]\n",
        "    self.DNAData.extend(self.ProjectDnaBsubtilisJRCData)\n",
        "    self.DNAData.extend(self.ProjectDnaBsubtilisLGLData)\n",
        "    self.DNAData.extend(self.ProjectDnaBsubtilisLHLData)\n",
        "    #self.DNADataRecords={}\n",
        "    \n",
        "    self.SampleDNAData= {}\n",
        "\n",
        "    prep_drive(not self.UseSampleData, [self.ProjectDir, self.ProjectDnaDir])\n",
        "\n",
        "    self.DownloadAndExtractData()\n",
        "    self.PrepSampleDNAData()\n",
        "\n",
        "  def DownloadAndExtractData(self):\n",
        "    if self.UseSampleData:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the sample Data\n",
        "      download_and_extract_file(self.SampleUrl, self.SampleBundle, self.SampleDir)\n",
        "    else:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the DNA library\n",
        "      download_and_extract_file(self.BsubtilisJRCBundleUrl, self.BsubtilisJRCBundle, self.ProjectDnaDir)\n",
        "      ##This is VERY LARGE, need to figure out if we really want data this large.\n",
        "      ##It caused me to run out of colab disk space.\n",
        "      #download_and_extract_file(self.BsubtilisLGLBundleUrl, self.BsubtilisLGLBundle, self.ProjectDnaDir)\n",
        "      download_and_extract_file(self.BsubtilisLHLBundleUrl, self.BsubtilisLHLBundle, self.ProjectDnaDir)\n",
        "\n",
        "  def PrepSampleDNAData(self, shuffle=False):\n",
        "    for dataFile in self.DNAData:\n",
        "      print(dataFile)\n",
        "      self.SampleDNAData[dataFile] = self.Encode(dataFile, self.Shape, shuffle)\n",
        "     \n",
        "  def Encode(self, dataFile, shape=None, shuffle=False):\n",
        "    def multiply(factor, *args):\n",
        "      for i in args:\n",
        "          factor = factor * i\n",
        "      return factor\n",
        "    if None == shape:\n",
        "      shape = self.Shape\n",
        "    sampleSize=multiply(1,shape)\n",
        "    Z = np.zeros((sampleSize),dtype='float32')\n",
        "    with open(dataFile, \"r\") as handle:\n",
        "      recordCount=0\n",
        "      for record in SeqIO.parse(handle, \"fastq\"):\n",
        "        #self.DNADataRecords[dataFile].append(record)\n",
        "        dl=[(0,(1,(2,3)[char!='g'])[char!='c'])[char!='a'] for char in record.lower()]\n",
        "        average=(sum(dl) / len(dl))/3\n",
        "        Z[recordCount]=average\n",
        "        recordCount+=1\n",
        "        if recordCount >= len(Z):\n",
        "          break\n",
        "    Z=np.interp(Z, (Z.min(), Z.max()), (0.0, 1.0))\n",
        "    if True == shuffle:\n",
        "      rng = np.random.default_rng()\n",
        "      rng.shuffle(Z)\n",
        "    return tf.reshape(tf.convert_to_tensor(Z, dtype=tf.float32), shape=shape )\n",
        "dna = DNASamples(useSampleData=False)"
      ],
      "execution_count": 667,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/DNAData/Bsubtilis-JRC/Bsubtilis-JRC.fastq\n",
            "/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/DNAData/Bsubtilis-LHL/Bsubtilis_S1_L001_R1_001.fastq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGfdMEVSFrQn"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Starting to build our GAN, based on the sample provided by TensorFlow\n",
        "#https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "#https://keras.io/examples/generative/dcgan_overriding_train_step/\n",
        "#https://medium.com/@mrgarg.rajat/implementing-stackgan-using-keras-a0a1b381125e\n",
        "class GAN(tf.keras.Model):\n",
        "  def __init__(self, discriminator, generator, latent_dim, trainingClass=\"\"):\n",
        "    super(GAN, self).__init__()\n",
        "    self.accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "    self.Checkpoint=None\n",
        "    self.CheckpointPrefix=\"./ckpt\"\n",
        "    self.TrainingClass=trainingClass\n",
        "    self.ModelDir=trainingClass\n",
        "\n",
        "  def Compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "    super(GAN, self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "  def __call__(self, inputs, training=None, mask=None):\n",
        "    return self.generator(inputs)\n",
        "\n",
        "  def SaveWeights(self):\n",
        "    gPath=self.ModelDir+\"Generator\"\n",
        "    dPath=self.ModelDir+\"Discriminator\"\n",
        "    self.generator.save_weights(gPath)\n",
        "    self.discriminator.save_weights(dPath)\n",
        "\n",
        "  def LoadWeights(self):\n",
        "    gPath=self.ModelDir+\"Generator\"\n",
        "    dPath=self.ModelDir+\"Discriminator\"\n",
        "    if os.path.exists(gPath + \".index\"):\n",
        "      self.generator.load_weights(gPath)\n",
        "    if os.path.exists(dPath + \".index\"):\n",
        "      self.discriminator.load_weights(dPath)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"d_optimizer\": self.d_optimizer,\n",
        "            \"g_optimizer\": self.g_optimizer,\n",
        "            \"loss_fn\": self.loss_fn,\n",
        "            \"discriminator\": self.discriminator ,\n",
        "            \"generator\": self.generator,\n",
        "            \"latent_dim\": self.latent_dim,\n",
        "            }\n",
        "\n",
        "  def Summary(self):\n",
        "    self.generator.summary()\n",
        "    self.discriminator.summary()\n",
        "\n",
        "  def DisplayImage(self,filename):\n",
        "    return PIL.Image.open(filename)\n",
        "\n",
        "  def DisplayImageArray(self,image):\n",
        "    image = tf.constant(image)\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "    return PIL.Image.fromarray(image.numpy())\n",
        "\n",
        "  # function to be applied to each element in a dataset\n",
        "  def convert_to_gray(image, label):    # note each element is comprised of an image and a label\n",
        "    return tf.reduce_mean(image, axis=-1), label\n",
        "\n",
        "  def train_step(self, real_images):\n",
        "    if isinstance(real_images, tuple):\n",
        "      real_images = real_images[0]\n",
        "    # Sample random points in the latent space\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "    # Decode them to fake images\n",
        "    generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "    # Combine them with real images\n",
        "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "    # Assemble labels discriminating real from fake images\n",
        "    labels = tf.concat(\n",
        "        [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "    )\n",
        "    # Add random noise to the labels - important trick!\n",
        "    # discussed here: https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\n",
        "    labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "    # Train the discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.discriminator(combined_images)\n",
        "      d_loss = self.loss_fn(labels, predictions)\n",
        "    grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "    self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "    f = tf.where(predictions > 0.5, 1, 0)\n",
        "    y = tf.where(labels > 0.5, 1, 0)\n",
        "    hits = tf.equal(y, f)\n",
        "    d_acc = tf.reduce_mean( tf.cast(hits, dtype=tf.float32) )\n",
        "\n",
        "    # Sample random points in the latent space\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "    # Assemble labels that say \"all real images\"\n",
        "    misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "    # Train the generator (note that we should *not* update the weights\n",
        "    # of the discriminator)!\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "      g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "    self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "    if None != self.Checkpoint:\n",
        "      self.Checkpoint.save(file_prefix=self.CheckpointPrefix)\n",
        "\n",
        "    return {\"d_loss\": d_loss, \"d_acc\":d_acc, \"g_loss\": g_loss}\n"
      ],
      "execution_count": 668,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gNQUIKYtURs"
      },
      "source": [
        "class GANMonitor(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, num_img=3, latent_dim=128, image_dir=\"\", name=\"\"):\n",
        "    self.num_img = num_img\n",
        "    self.latent_dim = latent_dim\n",
        "    self.image_dir = image_dir\n",
        "    self.name=name\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "    generated_images = self.model.generator(random_latent_vectors)\n",
        "    generated_images *= 255\n",
        "    generated_images.numpy()\n",
        "    if 0 == epoch%25:\n",
        "      for i in range(self.num_img):\n",
        "        img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "        img.save(self.image_dir+\"/genimg_%s_%03d_%d.png\" % (self.name,epoch, i))\n"
      ],
      "execution_count": 669,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWjkWtFdWiDC"
      },
      "source": [
        "#import tensorflow as tf\n",
        "#class ConditioningAugmentation(tf.keras.Model):\n",
        "#  def __init__(self, conditionVariable):\n",
        "#    self.condition = tf.keras.Sequential(\n",
        "#        [\n",
        "#          tf.keras.Input(shape=(128)),\n",
        "#          tf.keras.layers.Flatten(),\n",
        "#          tf.keras.layers.Dense(256),\n",
        "#          tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "#        ], \n",
        "#        name=\"ConditioningAugmentation\"\n",
        "#        )\n",
        "#    self.mean = self.condition[:, :128]\n",
        "#    self.log_sigma = self.condition[:, 128:]"
      ],
      "execution_count": 670,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgx8PnSPNQsM"
      },
      "source": [
        "import tensorflow as tf\n",
        "class StackGANStage(GAN):\n",
        "  def __init__ (self, name, trainingClass, \n",
        "                discriminator, generator,\n",
        "                batch_size, latent_dim, image_shape):\n",
        "    self.image_shape=image_shape\n",
        "    self.batch_size = batch_size\n",
        "    self.validation_split=0.3\n",
        "    self.seed=5549\n",
        "    self.train_ds=None\n",
        "    self.test_ds=None\n",
        "    self.normalized_train_ds=None\n",
        "    # finish construction of a basic GAN\n",
        "    super(StackGANStage, self).__init__(\n",
        "      discriminator=discriminator,\n",
        "      generator=generator,\n",
        "      latent_dim=latent_dim,\n",
        "      trainingClass=trainingClass)\n",
        "        \n",
        "  def PrepTrainingData(self, landscape_data_dir):\n",
        "    image_count = len(list(landscape_data_dir.glob('*/*.jpg')))\n",
        "    #print(image_count)\n",
        "    landscape_photos = list(landscape_data_dir.glob('photos/*.jpg'))\n",
        "    #PIL.Image.open(str(landscape_photos[0]))\n",
        "\n",
        "    if (image_count < (self.batch_size*5)):\n",
        "      self.batch_size = int(image_count/5)\n",
        "\n",
        "    self.train_ds=None\n",
        "    self.test_ds=None\n",
        "    if (0 < self.validation_split):\n",
        "      self.train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        landscape_data_dir,\n",
        "        validation_split=self.validation_split,\n",
        "        subset=\"training\",\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        seed=self.seed,\n",
        "        image_size=(self.image_shape[0], self.image_shape[1]),\n",
        "        batch_size=self.batch_size)\n",
        "      class_names = self.train_ds.class_names\n",
        "      #print(class_names)\n",
        "\n",
        "      self.test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        landscape_data_dir,\n",
        "        validation_split=self.validation_split,\n",
        "        subset=\"validation\",\n",
        "        color_mode='rgb',\n",
        "        seed=self.seed,\n",
        "        image_size=(self.image_shape[0], self.image_shape[1]),\n",
        "        batch_size=self.batch_size)\n",
        "    else:\n",
        "      self.train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        landscape_data_dir,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        seed=self.seed,\n",
        "        image_size=(self.image_shape[0], self.image_shape[1]),\n",
        "        batch_size=self.batch_size)\n",
        "      class_names = self.train_ds.class_names  \n",
        "    \n",
        "    normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "    # normalize the already shuffled training data\n",
        "    self.normalized_train_ds = self.train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    #Don't flatten, so that a convolution layer can be run\n",
        "    #flatten_layer = tf.keras.layers.Flatten()\n",
        "    #self.image_batch, self.labels_batch = next(iter(self.normalized_train_ds))\n",
        "    #first_image = image_batch[0]\n",
        "    #print(np.min(first_image), np.max(first_image))\n",
        "\n",
        "  def DisplaySamples(self):\n",
        "    class_names = self.train_ds.class_names\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    for images, labels in self.train_ds.take(1):\n",
        "      for i in range(4):\n",
        "        ax = plt.subplot(2, 2, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "  def Compile(self):\n",
        "    super(StackGANStage, self).Compile(\n",
        "      d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "      g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "      loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
        "    \n",
        "  def Train(self,epochs=600, name=\"\"):\n",
        "    self.fit(self.normalized_train_ds, epochs=epochs\n",
        "               ,callbacks=[GANMonitor(num_img=2, latent_dim=self.latent_dim, image_dir=self.GeneratedImageDir, name=name)]\n",
        "              )\n"
      ],
      "execution_count": 671,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6AzG5va5PS9"
      },
      "source": [
        "class StackGANStageI(StackGANStage):\n",
        "  def __init__ (self, name, trainingClass, batch_size, latent_dim, image_shape):\n",
        "    generator = tf.keras.Sequential(\n",
        "      [\n",
        "        tf.keras.Input(shape=(128)),\n",
        "        #Initial Input processing\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(int(image_shape[0]/16) * int(image_shape[0]/16) * 128 * 8),\n",
        "        tf.keras.layers.Reshape(\n",
        "            (int(image_shape[0]/16), int(image_shape[0]/16), 128 * 8),\n",
        "            input_shape=(int(image_shape[0]/16) * int(image_shape[0]/16) * 128 * 8,)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        \n",
        "        #UpSample\n",
        "        #tf.keras.layers.UpSampling2D(size=(8, 8), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), name=str(name)+\"_GConv-1\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "\n",
        "        #UpSample\n",
        "        #tf.keras.layers.UpSampling2D(size=(16, 16), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), name=str(name)+\"_GConv-2\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "\n",
        "        #UpSample\n",
        "        #tf.keras.layers.UpSampling2D(size=(32, 32), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), name=str(name)+\"_GConv-3\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        \n",
        "        #UpSample and output\n",
        "        #tf.keras.layers.UpSampling2D(size=(64, 64), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=image_shape[2], kernel_size=(3,3), name=str(name)+\"_GConv-4\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.Activation(tf.nn.tanh)\n",
        "      ], \n",
        "      name=name + \"_Generator\"\n",
        "    )\n",
        "    \n",
        "    discriminator = tf.keras.Sequential(\n",
        "      [\n",
        "        # generator input\n",
        "        tf.keras.Input(shape=image_shape),\n",
        "        tf.keras.layers.Conv2D(filters=image_shape[0], kernel_size=int(image_shape[0]/16), name=str(name)+\"_DConv-1\", padding=\"same\", strides=2, use_bias=False),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "       \n",
        "        #DownSample\n",
        "        #tf.keras.layers.DownSampling2D(size=(32, 32), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=2*image_shape[0], kernel_size=int(image_shape[0]/16), name=str(name)+\"_DConv-2\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "       \n",
        "        #DownSample\n",
        "        #tf.keras.layers.UpSampling2D(size=(32, 32), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=4*image_shape[0], kernel_size=int(image_shape[0]/16), name=str(name)+\"_DConv-3\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "       \n",
        "        #DownSample\n",
        "        #tf.keras.layers.DownSampling2D(size=(32, 32), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=8*image_shape[0], kernel_size=int(image_shape[0]/16), name=str(name)+\"_DConv-4\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        #Output\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1),\n",
        "      ], \n",
        "      name=name + \"_Discriminator\"\n",
        "      )  \n",
        "    \n",
        "    # finish construction of a StackGAN\n",
        "    super(StackGANStageI, self).__init__(\n",
        "      name, trainingClass, \n",
        "      discriminator, generator,\n",
        "      batch_size, latent_dim, image_shape)\n"
      ],
      "execution_count": 672,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf7RjaahSSKO"
      },
      "source": [
        "class StackGANStageII(StackGANStage):\n",
        "  def __init__ (self, name, trainingClass, batch_size, latent_dim, image_shape):\n",
        "    generator = tf.keras.Sequential(\n",
        "      [\n",
        "      ], \n",
        "      name=name + \"_Generator\"\n",
        "    )\n",
        "    \n",
        "    discriminator = tf.keras.Sequential(\n",
        "      [\n",
        "      ], \n",
        "      name=name + \"_Discriminator\"\n",
        "      )  \n",
        "    \n",
        "    # finish construction of a StackGAN\n",
        "    super(StackGANStageII, self).__init__(\n",
        "      name, trainingClass, \n",
        "      discriminator, generator,\n",
        "      batch_size, latent_dim, image_shape)\n"
      ],
      "execution_count": 673,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCYGpfA8tv6f"
      },
      "source": [
        "class GANDinsky(object):\n",
        "  def __init__(self, trainingClass, useSampleData, prepForTraining=False, projectDir=None):\n",
        "    # Prep GANdisky specific data members\n",
        "    self.TrainingParam={\n",
        "        \"batch_size\":64,\n",
        "        \"stageIOutputHeight\":64,\n",
        "        \"stageIOutputWidth\":64,\n",
        "        \"stageIOutputDepth\":3,\n",
        "        \"stageIIOutputHeight\":256,\n",
        "        \"stageIIOutputWidth\":256,\n",
        "        \"stageIIOutputDepth\":3,\n",
        "      }\n",
        "    latent_dim = 128\n",
        "    self.StageI=StackGANStageI(\"LandScape_StageI\", trainingClass, self.TrainingParam[\"batch_size\"], latent_dim,\n",
        "                                image_shape=(self.TrainingParam[\"stageIOutputHeight\"], \n",
        "                                self.TrainingParam[\"stageIOutputWidth\"], \n",
        "                                self.TrainingParam[\"stageIOutputDepth\"]))\n",
        "    self.StageII=StackGANStageII(\"LandScape_StageII\", trainingClass, self.TrainingParam[\"batch_size\"], latent_dim, \n",
        "                          image_shape=(self.TrainingParam[\"stageIIOutputHeight\"], \n",
        "                          self.TrainingParam[\"stageIIOutputWidth\"], \n",
        "                          self.TrainingParam[\"stageIIOutputDepth\"]))\n",
        "    \n",
        "    self.UseSampleData = useSampleData\n",
        "    self.ProjectDir=projectDir\n",
        "    if None == self.ProjectDir:\n",
        "      self.ProjectDir=\"/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/\"\n",
        "      if True == self.UseSampleData:\n",
        "        # If using sample data, overwrite the parameters\n",
        "        self.ProjectDir=\"/content/ChernobylBlueChillers/\"\n",
        "    self.StageI.ModelDir = self.ProjectDir + \"model/\" + trainingClass + \"/StageI/\"\n",
        "    self.StageI.GeneratedImageDir=self.ProjectDir + \"generatedImages/\" + trainingClass + \"/StageI/\"\n",
        "    self.StageII.ModelDir = self.ProjectDir + \"model/\" + trainingClass + \"/StageII/\"\n",
        "    self.StageII.GeneratedImageDir=self.ProjectDir + \"generatedImages/\" + trainingClass + \"/StageII/\"\n",
        "\n",
        "    #self.ModelDir=self.ProjectDir + \"model/\" + trainingClass + \"/\"\n",
        "    #self.GeneratedImageDir=self.ProjectDir + \"generatedImages/\" + trainingClass + \"/\"\n",
        "\n",
        "    self.SampleUrl=\"https://drive.google.com/uc?export=download&id=1ZPY_-CFnrCiDucbM0kmQB0G6rgOjoXBs\"\n",
        "    self.SampleDir=self.ProjectDir\n",
        "    self.SampleBundle=self.SampleDir + 'SampleData.zip'\n",
        "\n",
        "    #photo directory information\n",
        "    self.ProjectLandscapePhotoDir=self.ProjectDir + \"landscape/photos/\"\n",
        "    self.ProjectLandscapeDir=self.ProjectDir + \"landscape/\"\n",
        "    #https://www.kaggle.com/arnaud58/landscape-pictures\n",
        "    self.PhotoBundleUrl=\"https://storage.googleapis.com/kaggle-data-sets/298806/1217826/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210228%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210228T202950Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=16593e15698fc6080632d46623d25f3a5e2181fe3d6a94eb70f27dba657ded3b4d1b73c850b64a96fa294d7ca2404794577386743f72f452c50d49073411729bcf16404c1695fffb9a6e9aff075cfa54906ac9b96352d4fb28f546a1f57a52b97b205541aaa7f60325e4d9a7e7054ec0d099b760cab8110f6517ec401c9c810bbee66a4bc2566e745da43d3c7d4957e10301d72bd086169789a0c184d90f1e5f68b96d8c16707c125ee5e83035a016bdf736b7a347384e88392395615d5cadd1274c535e956cdf00e27c4d78d07160b861886760f5d84e2e689470dd761976788671f6b08caf86a15fb3f87c79f39a66bf6eba6a02b8150daabe1297d6e5a2fc\"\n",
        "    self.PhotoBundle=self.ProjectLandscapePhotoDir + 'kaggle-landscape_photos.zip'\n",
        "\n",
        "    prep_drive(not self.UseSampleData, [self.StageI.ModelDir, self.StageII.ModelDir])\n",
        "    os.chdir(self.ProjectDir)\n",
        "\n",
        "    if True == prepForTraining:\n",
        "      self.PrepForTraining()\n",
        "\n",
        "  def __call__(self, inputs, training=None, mask=None):\n",
        "    SI = self.StageI(inputs,training,mask)\n",
        "    return SI #self.StageII(SI, training, mask)\n",
        "    \n",
        "  def PrepForTraining(self):\n",
        "    prep_drive(not self.UseSampleData, \n",
        "                [self.ProjectDir, self.ProjectLandscapePhotoDir, \n",
        "                self.StageI.GeneratedImageDir,self.StageII.GeneratedImageDir])\n",
        "    os.chdir(self.ProjectDir)\n",
        "    self.DownloadAndExtractData()\n",
        "\n",
        "    self.StageI.PrepTrainingData(pathlib.Path(self.ProjectLandscapeDir))\n",
        "    self.StageII.PrepTrainingData(pathlib.Path(self.ProjectLandscapeDir))\n",
        "    self.Compile()\n",
        "\n",
        "  def DownloadAndExtractData(self):\n",
        "    if self.UseSampleData:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the sample Data\n",
        "      download_and_extract_file(self.SampleUrl, self.SampleBundle, self.SampleDir)\n",
        "    else:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the image library\n",
        "      download_and_extract_file(self.PhotoBundleUrl, self.PhotoBundle, self.ProjectLandscapePhotoDir)\n",
        "\n",
        "  def get_config(self):\n",
        "    retVal = super(GANDinsky, self).get_config()\n",
        "    retVal[\"TrainingParam\"]=self.TrainingParam\n",
        "    retVal[\"UseSampleData\"]=self.UseSampleData\n",
        "    retVal[\"SampleUrl\"]=self.SampleUrl\n",
        "    retVal[\"SampleDir\"]=self.SampleDir\n",
        "    retVal[\"SampleBundle\"]=self.SampleBundle\n",
        "    retVal[\"ProjectLandscapePhotoDir\"]=self.ProjectLandscapePhotoDir\n",
        "    retVal[\"ProjectLandscapeDir\"]=self.ProjectLandscapeDir\n",
        "    retVal[\"PhotoBundleUrl\"]=self.PhotoBundleUrl\n",
        "    retVal[\"PhotoBundle\"]=self.PhotoBundle\n",
        "    return retVal\n",
        "\n",
        "  def DisplaySamples(self):\n",
        "    self.StageI.DisplaySamples()\n",
        "    #self.StageII.DisplaySamples()\n",
        "\n",
        "  def LoadWeights(self):\n",
        "    self.StageI.LoadWeights()\n",
        "    #self.StageII.loadWeights()\n",
        "\n",
        "  def SaveWeights(self):\n",
        "    self.StageI.SaveWeights()\n",
        "    #self.StageII.saveWeights()\n",
        "\n",
        "  def Compile(self):\n",
        "    self.StageI.Compile()\n",
        "    #self.StageII.Compile()\n",
        "  \n",
        "  def Summary(self):\n",
        "    self.StageI.Summary()\n",
        "    #self.StageII.summary()\n",
        "\n",
        "  def Train(self,epochs=100, name=\"\"):\n",
        "    self.StageI.Train(epochs=epochs, name=name)\n",
        "    #self.StageII.Train(epochs=epochs, name=name)\n",
        "\n"
      ],
      "execution_count": 674,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wXyBO1txUqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6a8a1a-7f88-401c-d326-445d76034140"
      },
      "source": [
        "gan = GANDinsky(trainingClass=\"landscape_photo\", useSampleData=False, prepForTraining=True)\n",
        "gan.LoadWeights()\n",
        "gan.DisplaySamples()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4319 files belonging to 1 classes.\n",
            "Using 3024 files for training.\n",
            "Found 4319 files belonging to 1 classes.\n",
            "Using 1295 files for validation.\n",
            "Found 4319 files belonging to 1 classes.\n",
            "Using 3024 files for training.\n",
            "Found 4319 files belonging to 1 classes.\n",
            "Using 1295 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmAJFBYwLu2B"
      },
      "source": [
        "iterations=10\n",
        "initialIteration=51\n",
        "for i in range(initialIteration,initialIteration+iterations):\n",
        "  gan.Train(20, gan.StageI.TrainingClass + str(i))\n",
        "  gan.SaveWeights()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PvonkRxwWki"
      },
      "source": [
        "generated_images = gan(dna.SampleDNAData[dna.DNAData[1]])\n",
        "generated_images\n",
        "gan.StageI.DisplayImageArray(generated_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}