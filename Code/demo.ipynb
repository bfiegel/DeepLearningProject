{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISE 6380: Chernobyl Blue Chillers - GANdinsky.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHE8cdQMTO1U",
        "outputId": "15cc616c-16bb-4dca-8491-52d0a9dc2856"
      },
      "source": [
        "!pip install biopython\n",
        "\n",
        "import Bio\n",
        "from Bio import SeqIO\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import os\n",
        "import pathlib\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "import urllib.request\n",
        "from zipfile import ZipFile\n",
        "\n",
        "#import shutil\n",
        "#shutil.rmtree('/content/drive')\n",
        "os.chdir(\"/\")\n",
        "os.getcwd()\n",
        "\n",
        "def prep_drive(doMount, dirsToMake):\n",
        "  #mount google drive for longterm storage\n",
        "  if True == doMount:\n",
        "    mountPoint='/content/drive/'\n",
        "    if not os.path.exists(mountPoint):\n",
        "      drive.mount(mountPoint, force_remount=False)\n",
        "\n",
        "  for d in dirsToMake:\n",
        "    if not os.path.isdir(d):\n",
        "      os.makedirs(d)\n",
        "\n",
        "def download_and_extract_file(url, local_bundle_path, extraction_directory='.'):\n",
        "  initial_directory = os.getcwd()\n",
        "  os.chdir(extraction_directory)\n",
        "  try:\n",
        "    if not os.path.exists(local_bundle_path):\n",
        "      # download the dataset\n",
        "      urllib.request.urlretrieve(url,local_bundle_path )\n",
        "      \n",
        "      if local_bundle_path.endswith('.zip'):\n",
        "        # extract the dataset and store it on google drive\n",
        "        with ZipFile(local_bundle_path, 'r') as zip:\n",
        "          zip.extractall()\n",
        "      elif local_bundle_path.endswith('.tar.gz') or local_bundle_path.endswith('.tgz'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:gz\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      elif local_bundle_path.endswith('.tar'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      elif path.endswith('.tar.bz2') or path.endswith('.tbz'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:bz2\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      else: \n",
        "        raise Exception(local_bundle_path + \" has an unrecognized file extension\")\n",
        "  finally:\n",
        "    os.chdir(initial_directory)\n",
        "\n",
        "def noop():\n",
        "  return None\n"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (1.78)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdKiccT1xFUi",
        "outputId": "2fa452ae-9bc9-469b-f652-cb8266138d28"
      },
      "source": [
        "class DNASamples(object):\n",
        "  def __init__(self, useSampleData, shape=(1,128), projectDir=None):\n",
        "    self.Shape=shape\n",
        "    self.UseSampleData = useSampleData\n",
        "    self.ProjectDir=projectDir\n",
        "    if None == self.ProjectDir:\n",
        "      self.ProjectDir=\"/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/\"\n",
        "      if True == self.UseSampleData:\n",
        "        # If using sample data, overwrite the parameters\n",
        "        self.ProjectDir=\"/content/ChernobylBlueChillers/\"\n",
        "\n",
        "    self.SampleUrl=\"https://drive.google.com/uc?export=download&id=1ZPY_-CFnrCiDucbM0kmQB0G6rgOjoXBs\"\n",
        "    self.SampleDir=self.ProjectDir\n",
        "    self.SampleBundle=self.SampleDir + 'SampleData.zip'\n",
        "\n",
        "    self.ProjectDnaDir=self.ProjectDir + \"DNAData/\"\n",
        "    #Bsubtilis_JRC DNA data\n",
        "    self.BsubtilisJRCBundleUrl=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-JRC.tgz\"\n",
        "    self.BsubtilisJRCBundle = self.ProjectDnaDir + 'Bsubtilis-JRC.tgz'\n",
        "    self.ProjectDnaBsubtilisJRCDir=self.ProjectDnaDir + \"Bsubtilis-JRC/\"\n",
        "    self.ProjectDnaBsubtilisJRCData = [self.ProjectDnaBsubtilisJRCDir + \"Bsubtilis-JRC.fastq\"]\n",
        "\n",
        "    #Bsubtilis_LGL DNA data\n",
        "    self.BsubtilisLGLBundleUrl=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-LGL.tgz\"\n",
        "    self.BsubtilisLGLBundle = self.ProjectDnaDir + 'Bsubtilis-LGL.tgz'\n",
        "    self.ProjectDnaBsubtilisLGLDir=self.ProjectDnaDir + \"Bsubtilis-LGL/\"\n",
        "    self.ProjectDnaBsubtilisLGLData = []#[self.ProjectDnaBsubtilisLGLDir + \"Bsubtilis-LGL.fastq\"]\n",
        "\n",
        "    #Bsubtilis_LHL DNA data\n",
        "    self.BsubtilisLHLBundleUrl=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-LHL.tgz\"\n",
        "    self.BsubtilisLHLBundle = self.ProjectDnaDir + 'Bsubtilis-LHL.tgz'\n",
        "    self.ProjectDnaBsubtilisLHLDir=self.ProjectDnaDir + \"Bsubtilis-LHL/\"\n",
        "    self.ProjectDnaBsubtilisLHLData = [self.ProjectDnaBsubtilisLHLDir + \"Bsubtilis_S1_L001_R1_001.fastq\"]\n",
        "\n",
        "    if True == self.UseSampleData:\n",
        "      # If using sample data, overwrite the parameters\n",
        "      self.ProjectDnaBsubtilisJRCData = [self.ProjectDnaBsubtilisJRCDir + \"Bsubtilis-JRC-truncated.fastq\"]\n",
        "      self.ProjectDnaBsubtilisLHLData = [self.ProjectDnaBsubtilisLHLDir + \"Bsubtilis_S1_L001_R1_001-truncated.fastq\"]\n",
        "\n",
        "    self.DNAData=[]\n",
        "    self.DNAData.extend(self.ProjectDnaBsubtilisJRCData)\n",
        "    self.DNAData.extend(self.ProjectDnaBsubtilisLGLData)\n",
        "    self.DNAData.extend(self.ProjectDnaBsubtilisLHLData)\n",
        "    #self.DNADataRecords={}\n",
        "    \n",
        "    self.SampleDNAData= {}\n",
        "\n",
        "    prep_drive(not self.UseSampleData, [self.ProjectDir, self.ProjectDnaDir])\n",
        "\n",
        "    self.DownloadAndExtractData()\n",
        "    self.PrepSampleDNAData()\n",
        "\n",
        "  def DownloadAndExtractData(self):\n",
        "    if self.UseSampleData:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the sample Data\n",
        "      download_and_extract_file(self.SampleUrl, self.SampleBundle, self.SampleDir)\n",
        "    else:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the DNA library\n",
        "      download_and_extract_file(self.BsubtilisJRCBundleUrl, self.BsubtilisJRCBundle, self.ProjectDnaDir)\n",
        "      ##This is VERY LARGE, need to figure out if we really want data this large.\n",
        "      ##It caused me to run out of colab disk space.\n",
        "      #download_and_extract_file(self.BsubtilisLGLBundleUrl, self.BsubtilisLGLBundle, self.ProjectDnaDir)\n",
        "      download_and_extract_file(self.BsubtilisLHLBundleUrl, self.BsubtilisLHLBundle, self.ProjectDnaDir)\n",
        "\n",
        "  def PrepSampleDNAData(self, shuffle=False):\n",
        "    for dataFile in self.DNAData:\n",
        "      print(dataFile)\n",
        "      self.SampleDNAData[dataFile] = self.Encode(dataFile, self.Shape, shuffle)\n",
        "     \n",
        "  def Encode(self, dataFile, shape=None, shuffle=False):\n",
        "    def multiply(factor, *args):\n",
        "      for i in args:\n",
        "          factor = factor * i\n",
        "      return factor\n",
        "    if None == shape:\n",
        "      shape = self.Shape\n",
        "    sampleSize=multiply(1,shape)\n",
        "    Z = np.zeros((sampleSize),dtype='float32')\n",
        "    with open(dataFile, \"r\") as handle:\n",
        "      recordCount=0\n",
        "      for record in SeqIO.parse(handle, \"fastq\"):\n",
        "        #self.DNADataRecords[dataFile].append(record)\n",
        "        dl=[(0,(1,(2,3)[char!='g'])[char!='c'])[char!='a'] for char in record.lower()]\n",
        "        average=(sum(dl) / len(dl))/3\n",
        "        Z[recordCount]=average\n",
        "        recordCount+=1\n",
        "        if recordCount >= len(Z):\n",
        "          break\n",
        "    Z=np.interp(Z, (Z.min(), Z.max()), (0.0, 1.0))\n",
        "    if True == shuffle:\n",
        "      rng = np.random.default_rng()\n",
        "      rng.shuffle(Z)\n",
        "    return tf.reshape(tf.convert_to_tensor(Z, dtype=tf.float32), shape=shape )\n",
        "dna = DNASamples(useSampleData=True)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ChernobylBlueChillers/DNAData/Bsubtilis-JRC/Bsubtilis-JRC-truncated.fastq\n",
            "/content/ChernobylBlueChillers/DNAData/Bsubtilis-LHL/Bsubtilis_S1_L001_R1_001-truncated.fastq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGfdMEVSFrQn"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Starting to build our GAN, based on the sample provided by TensorFlow\n",
        "#https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "#https://keras.io/examples/generative/dcgan_overriding_train_step/\n",
        "#https://medium.com/@mrgarg.rajat/implementing-stackgan-using-keras-a0a1b381125e\n",
        "class GAN(tf.keras.Model):\n",
        "  def __init__(self, discriminator, generator, latent_dim, trainingClass=\"\"):\n",
        "    super(GAN, self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "    self.Checkpoint=None\n",
        "    self.CheckpointPrefix=\"./ckpt\"\n",
        "    self.TrainingClass=trainingClass\n",
        "    self.ModelDir=trainingClass\n",
        "\n",
        "  def Compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "    super(GAN, self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "  def __call__(self, inputs, training=None, mask=None):\n",
        "    return self.generator(inputs)\n",
        "\n",
        "  def SaveWeights(self):\n",
        "    gPath=self.ModelDir+\"Generator\"\n",
        "    dPath=self.ModelDir+\"Discriminator\"\n",
        "    self.generator.save_weights(gPath)\n",
        "    self.discriminator.save_weights(dPath)\n",
        "\n",
        "  def LoadWeights(self):\n",
        "    gPath=self.ModelDir+\"Generator\"\n",
        "    dPath=self.ModelDir+\"Discriminator\"\n",
        "    if os.path.exists(gPath + \".index\"):\n",
        "      self.generator.load_weights(gPath)\n",
        "    if os.path.exists(dPath + \".index\"):\n",
        "      self.discriminator.load_weights(dPath)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"d_optimizer\": self.d_optimizer,\n",
        "            \"g_optimizer\": self.g_optimizer,\n",
        "            \"loss_fn\": self.loss_fn,\n",
        "            \"discriminator\": self.discriminator ,\n",
        "            \"generator\": self.generator,\n",
        "            \"latent_dim\": self.latent_dim,\n",
        "            }\n",
        "\n",
        "  def Summary(self):\n",
        "    self.generator.summary()\n",
        "    self.discriminator.summary()\n",
        "\n",
        "  def DisplayImage(self,filename):\n",
        "    return PIL.Image.open(filename)\n",
        "\n",
        "  def DisplayImageArray(self,image):\n",
        "    image = tf.constant(image)\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "    return PIL.Image.fromarray(image.numpy())\n",
        "\n",
        "  # function to be applied to each element in a dataset\n",
        "  def convert_to_gray(image, label):    # note each element is comprised of an image and a label\n",
        "    return tf.reduce_mean(image, axis=-1), label\n",
        "\n",
        "  def train_step(self, real_images):\n",
        "    if isinstance(real_images, tuple):\n",
        "      real_images = real_images[0]\n",
        "    # Sample random points in the latent space\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "    # Decode them to fake images\n",
        "    generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "    # Combine them with real images\n",
        "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "    # Assemble labels discriminating real from fake images\n",
        "    labels = tf.concat(\n",
        "        [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "    )\n",
        "    # Add random noise to the labels - important trick!\n",
        "    labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "    # Train the discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.discriminator(combined_images)\n",
        "      d_loss = self.loss_fn(labels, predictions)\n",
        "    grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "    self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "    # Sample random points in the latent space\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "    # Assemble labels that say \"all real images\"\n",
        "    misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "    # Train the generator (note that we should *not* update the weights\n",
        "    # of the discriminator)!\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "      g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "    self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "    if None != self.Checkpoint:\n",
        "      self.Checkpoint.save(file_prefix=self.CheckpointPrefix)\n",
        "\n",
        "    return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gNQUIKYtURs"
      },
      "source": [
        "class GANMonitor(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, num_img=3, latent_dim=128, image_dir=\"\", name=\"\"):\n",
        "    self.num_img = num_img\n",
        "    self.latent_dim = latent_dim\n",
        "    self.image_dir = image_dir\n",
        "    self.name=name\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "    generated_images = self.model.generator(random_latent_vectors)\n",
        "    generated_images *= 255\n",
        "    generated_images.numpy()\n",
        "    if 0 == epoch%25:\n",
        "      for i in range(self.num_img):\n",
        "        img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "        img.save(self.image_dir+\"/genimg_%s_%03d_%d.png\" % (self.name,epoch, i))\n"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWjkWtFdWiDC"
      },
      "source": [
        "#import tensorflow as tf\n",
        "#class ConditioningAugmentation(tf.keras.Model):\n",
        "#  def __init__(self, conditionVariable):\n",
        "#    self.condition = tf.keras.Sequential(\n",
        "#        [\n",
        "#          tf.keras.Input(shape=(128)),\n",
        "#          tf.keras.layers.Flatten(),\n",
        "#          tf.keras.layers.Dense(256),\n",
        "#          tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "#        ], \n",
        "#        name=\"ConditioningAugmentation\"\n",
        "#        )\n",
        "#    self.mean = self.condition[:, :128]\n",
        "#    self.log_sigma = self.condition[:, 128:]"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgx8PnSPNQsM"
      },
      "source": [
        "import tensorflow as tf\n",
        "class StackGANStage(GAN):\n",
        "  def __init__ (self, name, trainingClass, \n",
        "                discriminator, generator,\n",
        "                batch_size, latent_dim, image_shape):\n",
        "    self.image_shape=image_shape\n",
        "    self.batch_size = batch_size\n",
        "    self.validation_split=0.0\n",
        "    self.seed=5549\n",
        "    self.train_ds=None\n",
        "    self.test_ds=None\n",
        "    self.normalized_train_ds=None\n",
        "    # finish construction of a basic GAN\n",
        "    super(StackGANStage, self).__init__(\n",
        "      discriminator=discriminator,\n",
        "      generator=generator,\n",
        "      latent_dim=latent_dim,\n",
        "      trainingClass=trainingClass)\n",
        "        \n",
        "  def PrepTrainingData(self, landscape_data_dir):\n",
        "    image_count = len(list(landscape_data_dir.glob('*/*.jpg')))\n",
        "    #print(image_count)\n",
        "    landscape_photos = list(landscape_data_dir.glob('photos/*.jpg'))\n",
        "    #PIL.Image.open(str(landscape_photos[0]))\n",
        "\n",
        "    if (image_count < (self.batch_size*5)):\n",
        "      self.batch_size = int(image_count/5)\n",
        "\n",
        "    self.train_ds=None\n",
        "    self.test_ds=None\n",
        "    if (0 < self.validation_split):\n",
        "      self.train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        landscape_data_dir,\n",
        "        validation_split=self.validation_split,\n",
        "        subset=\"training\",\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        seed=self.seed,\n",
        "        image_size=(self.image_shape[0], self.image_shape[1]),\n",
        "        batch_size=self.batch_size)\n",
        "      class_names = self.train_ds.class_names\n",
        "      #print(class_names)\n",
        "\n",
        "      self.test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        landscape_data_dir,\n",
        "        validation_split=self.validation_split,\n",
        "        subset=\"validation\",\n",
        "        color_mode='rgb',\n",
        "        seed=self.seed,\n",
        "        image_size=(self.image_shape[0], self.image_shape[1]),\n",
        "        batch_size=self.batch_size)\n",
        "    else:\n",
        "      self.train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        landscape_data_dir,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        seed=self.seed,\n",
        "        image_size=(self.image_shape[0], self.image_shape[1]),\n",
        "        batch_size=self.batch_size)\n",
        "      class_names = self.train_ds.class_names  \n",
        "    \n",
        "    normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "    # normalize the already shuffled training data\n",
        "    self.normalized_train_ds = self.train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    #Don't flatten, so that a convolution layer can be run\n",
        "    #flatten_layer = tf.keras.layers.Flatten()\n",
        "    #self.image_batch, self.labels_batch = next(iter(self.normalized_train_ds))\n",
        "    #first_image = image_batch[0]\n",
        "    #print(np.min(first_image), np.max(first_image))\n",
        "\n",
        "  def DisplaySamples(self):\n",
        "    class_names = self.train_ds.class_names\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    for images, labels in self.train_ds.take(1):\n",
        "      for i in range(4):\n",
        "        ax = plt.subplot(2, 2, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "  def Compile(self):\n",
        "    super(StackGANStage, self).Compile(\n",
        "      d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "      g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "      loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
        "    \n",
        "  def Train(self,epochs=600, name=\"\"):\n",
        "    self.fit(self.normalized_train_ds, epochs=epochs\n",
        "               ,callbacks=[GANMonitor(num_img=2, latent_dim=self.latent_dim, image_dir=self.GeneratedImageDir, name=name)]\n",
        "              )\n"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6AzG5va5PS9"
      },
      "source": [
        "class StackGANStageI(StackGANStage):\n",
        "  def __init__ (self, name, trainingClass, batch_size, latent_dim, image_shape):\n",
        "    generator = tf.keras.Sequential(\n",
        "      [\n",
        "        tf.keras.Input(shape=(128)),\n",
        "        #Initial Input processing\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(int(image_shape[0]/16) * int(image_shape[0]/16) * 128 * 8),\n",
        "        tf.keras.layers.Reshape(\n",
        "            (int(image_shape[0]/16), int(image_shape[0]/16), 128 * 8),\n",
        "            input_shape=(int(image_shape[0]/16) * int(image_shape[0]/16) * 128 * 8,)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        \n",
        "        #UpSample\n",
        "        #tf.keras.layers.UpSampling2D(size=(8, 8), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), name=str(name)+\"_GConv-1\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "\n",
        "        #UpSample\n",
        "        #tf.keras.layers.UpSampling2D(size=(16, 16), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), name=str(name)+\"_GConv-2\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "\n",
        "        #UpSample\n",
        "        #tf.keras.layers.UpSampling2D(size=(32, 32), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), name=str(name)+\"_GConv-3\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        \n",
        "        #UpSample and output\n",
        "        #tf.keras.layers.UpSampling2D(size=(64, 64), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=image_shape[2], kernel_size=(3,3), name=str(name)+\"_GConv-4\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.Activation(tf.nn.tanh)\n",
        "      ], \n",
        "      name=name + \"_Generator\"\n",
        "    )\n",
        "    \n",
        "    discriminator = tf.keras.Sequential(\n",
        "      [\n",
        "        # generator input\n",
        "        tf.keras.Input(shape=image_shape),\n",
        "        tf.keras.layers.Conv2D(filters=image_shape[0], kernel_size=int(image_shape[0]/16), name=str(name)+\"_DConv-1\", padding=\"same\", strides=2, use_bias=False),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "       \n",
        "        #DownSample\n",
        "        #tf.keras.layers.DownSampling2D(size=(32, 32), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=2*image_shape[0], kernel_size=int(image_shape[0]/16), name=str(name)+\"_DConv-2\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "       \n",
        "        #DownSample\n",
        "        #tf.keras.layers.UpSampling2D(size=(32, 32), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=4*image_shape[0], kernel_size=int(image_shape[0]/16), name=str(name)+\"_DConv-3\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "       \n",
        "        #DownSample\n",
        "        #tf.keras.layers.DownSampling2D(size=(32, 32), data_format=None, interpolation='nearest'),\n",
        "        tf.keras.layers.Conv2D(filters=8*image_shape[0], kernel_size=int(image_shape[0]/16), name=str(name)+\"_DConv-4\", padding=\"same\", strides=1, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        #Output\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1),\n",
        "      ], \n",
        "      name=name + \"_Discriminator\"\n",
        "      )  \n",
        "    \n",
        "    # finish construction of a StackGAN\n",
        "    super(StackGANStageI, self).__init__(\n",
        "      name, trainingClass, \n",
        "      discriminator, generator,\n",
        "      batch_size, latent_dim, image_shape)\n"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf7RjaahSSKO"
      },
      "source": [
        "class StackGANStageII(StackGANStage):\n",
        "  def __init__ (self, name, trainingClass, batch_size, latent_dim, image_shape):\n",
        "    generator = tf.keras.Sequential(\n",
        "      [\n",
        "      ], \n",
        "      name=name + \"_Generator\"\n",
        "    )\n",
        "    \n",
        "    discriminator = tf.keras.Sequential(\n",
        "      [\n",
        "      ], \n",
        "      name=name + \"_Discriminator\"\n",
        "      )  \n",
        "    \n",
        "    # finish construction of a StackGAN\n",
        "    super(StackGANStageII, self).__init__(\n",
        "      name, trainingClass, \n",
        "      discriminator, generator,\n",
        "      batch_size, latent_dim, image_shape)\n"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCYGpfA8tv6f"
      },
      "source": [
        "class GANDinsky(object):\n",
        "  def __init__(self, trainingClass, useSampleData, prepForTraining=False, projectDir=None):\n",
        "    # Prep GANdisky specific data members\n",
        "    self.TrainingParam={\n",
        "        \"batch_size\":64,\n",
        "        \"stageIOutputHeight\":64,\n",
        "        \"stageIOutputWidth\":64,\n",
        "        \"stageIOutputDepth\":3,\n",
        "        \"stageIIOutputHeight\":256,\n",
        "        \"stageIIOutputWidth\":256,\n",
        "        \"stageIIOutputDepth\":3,\n",
        "      }\n",
        "    latent_dim = 128\n",
        "    self.StageI=StackGANStageI(\"LandScape_StageI\", trainingClass, self.TrainingParam[\"batch_size\"], latent_dim,\n",
        "                                image_shape=(self.TrainingParam[\"stageIOutputHeight\"], \n",
        "                                self.TrainingParam[\"stageIOutputWidth\"], \n",
        "                                self.TrainingParam[\"stageIOutputDepth\"]))\n",
        "    self.StageII=StackGANStageII(\"LandScape_StageII\", trainingClass, self.TrainingParam[\"batch_size\"], latent_dim, \n",
        "                          image_shape=(self.TrainingParam[\"stageIIOutputHeight\"], \n",
        "                          self.TrainingParam[\"stageIIOutputWidth\"], \n",
        "                          self.TrainingParam[\"stageIIOutputDepth\"]))\n",
        "    \n",
        "    self.UseSampleData = useSampleData\n",
        "    self.ProjectDir=projectDir\n",
        "    if None == self.ProjectDir:\n",
        "      self.ProjectDir=\"/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/\"\n",
        "      if True == self.UseSampleData:\n",
        "        # If using sample data, overwrite the parameters\n",
        "        self.ProjectDir=\"/content/ChernobylBlueChillers/\"\n",
        "    self.StageI.ModelDir = self.ProjectDir + \"model/\" + trainingClass + \"/StageI/\"\n",
        "    self.StageI.GeneratedImageDir=self.ProjectDir + \"generatedImages/\" + trainingClass + \"/StageI/\"\n",
        "    self.StageII.ModelDir = self.ProjectDir + \"model/\" + trainingClass + \"/StageII/\"\n",
        "    self.StageII.GeneratedImageDir=self.ProjectDir + \"generatedImages/\" + trainingClass + \"/StageII/\"\n",
        "\n",
        "    #self.ModelDir=self.ProjectDir + \"model/\" + trainingClass + \"/\"\n",
        "    #self.GeneratedImageDir=self.ProjectDir + \"generatedImages/\" + trainingClass + \"/\"\n",
        "\n",
        "    self.SampleUrl=\"https://drive.google.com/uc?export=download&id=1ZPY_-CFnrCiDucbM0kmQB0G6rgOjoXBs\"\n",
        "    self.SampleDir=self.ProjectDir\n",
        "    self.SampleBundle=self.SampleDir + 'SampleData.zip'\n",
        "\n",
        "    #photo directory information\n",
        "    self.ProjectLandscapePhotoDir=self.ProjectDir + \"landscape/photos/\"\n",
        "    self.ProjectLandscapeDir=self.ProjectDir + \"landscape/\"\n",
        "    #https://www.kaggle.com/arnaud58/landscape-pictures\n",
        "    self.PhotoBundleUrl=\"https://storage.googleapis.com/kaggle-data-sets/298806/1217826/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210228%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210228T202950Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=16593e15698fc6080632d46623d25f3a5e2181fe3d6a94eb70f27dba657ded3b4d1b73c850b64a96fa294d7ca2404794577386743f72f452c50d49073411729bcf16404c1695fffb9a6e9aff075cfa54906ac9b96352d4fb28f546a1f57a52b97b205541aaa7f60325e4d9a7e7054ec0d099b760cab8110f6517ec401c9c810bbee66a4bc2566e745da43d3c7d4957e10301d72bd086169789a0c184d90f1e5f68b96d8c16707c125ee5e83035a016bdf736b7a347384e88392395615d5cadd1274c535e956cdf00e27c4d78d07160b861886760f5d84e2e689470dd761976788671f6b08caf86a15fb3f87c79f39a66bf6eba6a02b8150daabe1297d6e5a2fc\"\n",
        "    self.PhotoBundle=self.ProjectLandscapePhotoDir + 'kaggle-landscape_photos.zip'\n",
        "\n",
        "    prep_drive(not self.UseSampleData, [self.StageI.ModelDir, self.StageII.ModelDir])\n",
        "    os.chdir(self.ProjectDir)\n",
        "\n",
        "    if True == prepForTraining:\n",
        "      self.PrepForTraining()\n",
        "\n",
        "  def __call__(self, inputs, training=None, mask=None):\n",
        "    SI = self.StageI(inputs,training,mask)\n",
        "    return SI #self.StageII(SI, training, mask)\n",
        "    \n",
        "  def PrepForTraining(self):\n",
        "    prep_drive(not self.UseSampleData, \n",
        "                [self.ProjectDir, self.ProjectLandscapePhotoDir, \n",
        "                self.StageI.GeneratedImageDir,self.StageII.GeneratedImageDir])\n",
        "    os.chdir(self.ProjectDir)\n",
        "    self.DownloadAndExtractData()\n",
        "\n",
        "    self.StageI.PrepTrainingData(pathlib.Path(self.ProjectLandscapeDir))\n",
        "    self.StageII.PrepTrainingData(pathlib.Path(self.ProjectLandscapeDir))\n",
        "    self.Compile()\n",
        "\n",
        "  def DownloadAndExtractData(self):\n",
        "    if self.UseSampleData:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the sample Data\n",
        "      download_and_extract_file(self.SampleUrl, self.SampleBundle, self.SampleDir)\n",
        "    else:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the image library\n",
        "      download_and_extract_file(self.PhotoBundleUrl, self.PhotoBundle, self.ProjectLandscapePhotoDir)\n",
        "\n",
        "  def get_config(self):\n",
        "    retVal = super(GANDinsky, self).get_config()\n",
        "    retVal[\"TrainingParam\"]=self.TrainingParam\n",
        "    retVal[\"UseSampleData\"]=self.UseSampleData\n",
        "    retVal[\"GeneratedImageDir\"]=self.GeneratedImageDir\n",
        "    retVal[\"SampleUrl\"]=self.SampleUrl\n",
        "    retVal[\"SampleDir\"]=self.SampleDir\n",
        "    retVal[\"SampleBundle\"]=self.SampleBundle\n",
        "    retVal[\"ProjectLandscapePhotoDir\"]=self.ProjectLandscapePhotoDir\n",
        "    retVal[\"ProjectLandscapeDir\"]=self.ProjectLandscapeDir\n",
        "    retVal[\"PhotoBundleUrl\"]=self.PhotoBundleUrl\n",
        "    retVal[\"PhotoBundle\"]=self.PhotoBundle\n",
        "    return retVal\n",
        "\n",
        "  def DisplaySamples(self):\n",
        "    self.StageI.DisplaySamples()\n",
        "    #self.StageII.DisplaySamples()\n",
        "\n",
        "  def LoadWeights(self):\n",
        "    self.StageI.LoadWeights()\n",
        "    #self.StageII.loadWeights()\n",
        "\n",
        "  def SaveWeights(self):\n",
        "    self.StageI.SaveWeights()\n",
        "    #self.StageII.saveWeights()\n",
        "\n",
        "  def Compile(self):\n",
        "    self.StageI.Compile()\n",
        "    #self.StageII.Compile()\n",
        "  \n",
        "  def Summary(self):\n",
        "    self.StageI.Summary()\n",
        "    #self.StageII.summary()\n",
        "\n",
        "  def Train(self,epochs=100, name=\"\"):\n",
        "    self.StageI.Train(epochs=epochs, name=name)\n",
        "    #self.StageII.Train(epochs=epochs, name=name)\n",
        "\n"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wXyBO1txUqr"
      },
      "source": [
        "gan = GANDinsky(trainingClass=\"landscape_photo\", useSampleData=True, prepForTraining=True)\n",
        "gan.LoadWeights()\n",
        "gan.DisplaySamples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmAJFBYwLu2B"
      },
      "source": [
        "iterations=1\n",
        "initialIteration=1\n",
        "for i in range(initialIteration,initialIteration+iterations):\n",
        "  gan.Train(599, gan.StageI.TrainingClass + str(i))\n",
        "  gan.SaveWeights()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PvonkRxwWki",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "1f29e4a4-46a4-473a-f443-58b6be01bc77"
      },
      "source": [
        "generated_images = gan(dna.SampleDNAData[dna.DNAData[1]])\n",
        "generated_images\n",
        "gan.StageI.DisplayImageArray(generated_images[0])"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F6356F16750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    }
  ]
}