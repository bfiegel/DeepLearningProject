{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISE 6380: Chernobyl Blue Chillers - GANdinsky.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHE8cdQMTO1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2404d30-d67c-4fac-f055-afcad01c4f24"
      },
      "source": [
        "!pip install biopython\n",
        "\n",
        "import Bio\n",
        "from Bio import SeqIO\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import os\n",
        "import pathlib\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "import urllib.request\n",
        "from zipfile import ZipFile\n",
        "\n",
        "#import shutil\n",
        "#shutil.rmtree('/content/drive')\n",
        "os.chdir(\"/\")\n",
        "os.getcwd()\n",
        "\n",
        "def prep_drive(doMount, dirsToMake):\n",
        "  #mount google drive for longterm storage\n",
        "  if True == doMount:\n",
        "    mountPoint='/content/drive/'\n",
        "    if not os.path.exists(mountPoint):\n",
        "      drive.mount(mountPoint, force_remount=False)\n",
        "\n",
        "  for d in dirsToMake:\n",
        "    if not os.path.isdir(d):\n",
        "      os.makedirs(d)\n",
        "\n",
        "def download_and_extract_file(url, local_bundle_path, extraction_directory='.'):\n",
        "  initial_directory = os.getcwd()\n",
        "  os.chdir(extraction_directory)\n",
        "  try:\n",
        "    if not os.path.exists(local_bundle_path):\n",
        "      # download the dataset\n",
        "      urllib.request.urlretrieve(url,local_bundle_path )\n",
        "      \n",
        "      if local_bundle_path.endswith('.zip'):\n",
        "        # extract the dataset and store it on google drive\n",
        "        with ZipFile(local_bundle_path, 'r') as zip:\n",
        "          zip.extractall()\n",
        "      elif local_bundle_path.endswith('.tar.gz') or local_bundle_path.endswith('.tgz'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:gz\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      elif local_bundle_path.endswith('.tar'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      elif path.endswith('.tar.bz2') or path.endswith('.tbz'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:bz2\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      else: \n",
        "        raise Exception(local_bundle_path + \" has an unrecognized file extension\")\n",
        "  finally:\n",
        "    os.chdir(initial_directory)\n",
        "\n",
        "def noop():\n",
        "  return None\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (1.78)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdKiccT1xFUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31cc87dc-8f44-43d6-bda2-4537e3500806"
      },
      "source": [
        "class DNASamples(object):\n",
        "  def __init__(self, useSampleData, shape=(1,128), projectDir=None):\n",
        "    self.Shape=shape\n",
        "    self.UseSampleData = useSampleData\n",
        "    self.ProjectDir=projectDir\n",
        "    if None == self.ProjectDir:\n",
        "      self.ProjectDir=\"/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/\"\n",
        "      if True == self.UseSampleData:\n",
        "        # If using sample data, overwrite the parameters\n",
        "        self.ProjectDir=\"/content/ChernobylBlueChillers/\"\n",
        "\n",
        "    self.SampleUrl=\"https://drive.google.com/uc?export=download&id=1ZPY_-CFnrCiDucbM0kmQB0G6rgOjoXBs\"\n",
        "    self.SampleDir=self.ProjectDir\n",
        "    self.SampleBundle=self.SampleDir + 'SampleData.zip'\n",
        "\n",
        "    self.ProjectDnaDir=self.ProjectDir + \"DNAData/\"\n",
        "    #Bsubtilis_JRC DNA data\n",
        "    self.BsubtilisJRCBundleUrl=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-JRC.tgz\"\n",
        "    self.BsubtilisJRCBundle = self.ProjectDnaDir + 'Bsubtilis-JRC.tgz'\n",
        "    self.ProjectDnaBsubtilisJRCDir=self.ProjectDnaDir + \"Bsubtilis-JRC/\"\n",
        "    self.ProjectDnaBsubtilisJRCData = [self.ProjectDnaBsubtilisJRCDir + \"Bsubtilis-JRC.fastq\"]\n",
        "\n",
        "    #Bsubtilis_LGL DNA data\n",
        "    self.BsubtilisLGLBundleUrl=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-LGL.tgz\"\n",
        "    self.BsubtilisLGLBundle = self.ProjectDnaDir + 'Bsubtilis-LGL.tgz'\n",
        "    self.ProjectDnaBsubtilisLGLDir=self.ProjectDnaDir + \"Bsubtilis-LGL/\"\n",
        "    self.ProjectDnaBsubtilisLGLData = []#[self.ProjectDnaBsubtilisLGLDir + \"Bsubtilis-LGL.fastq\"]\n",
        "\n",
        "    #Bsubtilis_LHL DNA data\n",
        "    self.BsubtilisLHLBundleUrl=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-LHL.tgz\"\n",
        "    self.BsubtilisLHLBundle = self.ProjectDnaDir + 'Bsubtilis-LHL.tgz'\n",
        "    self.ProjectDnaBsubtilisLHLDir=self.ProjectDnaDir + \"Bsubtilis-LHL/\"\n",
        "    self.ProjectDnaBsubtilisLHLData = [self.ProjectDnaBsubtilisLHLDir + \"Bsubtilis_S1_L001_R1_001.fastq\"]\n",
        "\n",
        "    if True == self.UseSampleData:\n",
        "      # If using sample data, overwrite the parameters\n",
        "      self.ProjectDnaBsubtilisJRCData = [self.ProjectDnaBsubtilisJRCDir + \"Bsubtilis-JRC-truncated.fastq\"]\n",
        "      self.ProjectDnaBsubtilisLHLData = [self.ProjectDnaBsubtilisLHLDir + \"Bsubtilis_S1_L001_R1_001-truncated.fastq\"]\n",
        "\n",
        "    self.DNAData=[]\n",
        "    self.DNAData.extend(self.ProjectDnaBsubtilisJRCData)\n",
        "    self.DNAData.extend(self.ProjectDnaBsubtilisLGLData)\n",
        "    self.DNAData.extend(self.ProjectDnaBsubtilisLHLData)\n",
        "    #self.DNADataRecords={}\n",
        "    \n",
        "    self.SampleDNAData= {}\n",
        "\n",
        "    prep_drive(not self.UseSampleData, [self.ProjectDir, self.ProjectDnaDir])\n",
        "\n",
        "    self.DownloadAndExtractData()\n",
        "    self.PrepSampleDNAData()\n",
        "\n",
        "  def DownloadAndExtractData(self):\n",
        "    if self.UseSampleData:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the sample Data\n",
        "      download_and_extract_file(self.SampleUrl, self.SampleBundle, self.SampleDir)\n",
        "    else:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the DNA library\n",
        "      download_and_extract_file(self.BsubtilisJRCBundleUrl, self.BsubtilisJRCBundle, self.ProjectDnaDir)\n",
        "      ##This is VERY LARGE, need to figure out if we really want data this large.\n",
        "      ##It caused me to run out of colab disk space.\n",
        "      #download_and_extract_file(self.BsubtilisLGLBundleUrl, self.BsubtilisLGLBundle, self.ProjectDnaDir)\n",
        "      download_and_extract_file(self.BsubtilisLHLBundleUrl, self.BsubtilisLHLBundle, self.ProjectDnaDir)\n",
        "\n",
        "  def PrepSampleDNAData(self, shuffle=False):\n",
        "    for dataFile in self.DNAData:\n",
        "      print(dataFile)\n",
        "      self.SampleDNAData[dataFile] = self.Encode(dataFile, self.Shape, shuffle)\n",
        "     \n",
        "  def Encode(self, dataFile, shape=None, shuffle=False):\n",
        "    def multiply(factor, *args):\n",
        "      for i in args:\n",
        "          factor = factor * i\n",
        "      return factor\n",
        "    if None == shape:\n",
        "      shape = self.Shape\n",
        "    sampleSize=multiply(1,shape)\n",
        "    Z = np.zeros((sampleSize),dtype='float32')\n",
        "    with open(dataFile, \"r\") as handle:\n",
        "      recordCount=0\n",
        "      for record in SeqIO.parse(handle, \"fastq\"):\n",
        "        #self.DNADataRecords[dataFile].append(record)\n",
        "        dl=[(0,(1,(2,3)[char!='g'])[char!='c'])[char!='a'] for char in record.lower()]\n",
        "        average=(sum(dl) / len(dl))/3\n",
        "        Z[recordCount]=average\n",
        "        recordCount+=1\n",
        "        if recordCount >= len(Z):\n",
        "          break\n",
        "    Z=np.interp(Z, (Z.min(), Z.max()), (0.0, 1.0))\n",
        "    if True == shuffle:\n",
        "      rng = np.random.default_rng()\n",
        "      rng.shuffle(Z)\n",
        "    return tf.reshape(tf.convert_to_tensor(Z, dtype=tf.float32), shape=shape )\n",
        "dna = DNASamples(useSampleData=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/DNAData/Bsubtilis-JRC/Bsubtilis-JRC.fastq\n",
            "/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/DNAData/Bsubtilis-LHL/Bsubtilis_S1_L001_R1_001.fastq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGfdMEVSFrQn"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Starting to build our GAN, based on the sample provided by TensorFlow\n",
        "#https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "#https://keras.io/examples/generative/dcgan_overriding_train_step/\n",
        "#https://medium.com/@mrgarg.rajat/implementing-stackgan-using-keras-a0a1b381125e\n",
        "class GAN(tf.keras.Model):\n",
        "  def __init__(self, desc, incoming_shape, outgoing_shape, trainingClass=\"\"):\n",
        "    super(GAN, self).__init__()\n",
        "    self.accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "    self.desc=desc\n",
        "    self.incoming_shape = incoming_shape\n",
        "    self.outgoing_shape = outgoing_shape\n",
        "    self.Checkpoint=None\n",
        "    self.CheckpointPrefix=\"./ckpt\"\n",
        "    self.TrainingClass=trainingClass\n",
        "    self.ModelDir=trainingClass\n",
        "\n",
        "    self.generator = self.GetGenerator()\n",
        "    self.discriminator = self.GetDiscriminator()\n",
        "\n",
        "  def GetGenerator(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "  def GetDiscriminator(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "  def Compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "    super(GAN, self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "  def __call__(self, inputs, training=None, mask=None):\n",
        "    return self.generator(inputs)\n",
        "\n",
        "  def SaveWeights(self):\n",
        "    gPath=self.ModelDir+\"Generator\"\n",
        "    dPath=self.ModelDir+\"Discriminator\"\n",
        "    self.generator.save_weights(gPath)\n",
        "    self.discriminator.save_weights(dPath)\n",
        "\n",
        "  def LoadWeights(self):\n",
        "    gPath=self.ModelDir+\"Generator\"\n",
        "    dPath=self.ModelDir+\"Discriminator\"\n",
        "    if os.path.exists(gPath + \".index\"):\n",
        "      self.generator.load_weights(gPath)\n",
        "    if os.path.exists(dPath + \".index\"):\n",
        "      self.discriminator.load_weights(dPath)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"d_optimizer\": self.d_optimizer,\n",
        "            \"g_optimizer\": self.g_optimizer,\n",
        "            \"loss_fn\": self.loss_fn,\n",
        "            \"discriminator\": self.discriminator ,\n",
        "            \"generator\": self.generator,\n",
        "            \"incoming_shape\": self.incoming_shape,\n",
        "            \"outgoing_shape\": self.outgoing_shape,\n",
        "            }\n",
        "\n",
        "  def Summary(self):\n",
        "    self.generator.summary()\n",
        "    self.discriminator.summary()\n",
        "\n",
        "  def DisplayImage(self,filename):\n",
        "    return PIL.Image.open(filename)\n",
        "\n",
        "  def DisplayImageArray(self,image):\n",
        "    image = tf.constant(image)\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "    return PIL.Image.fromarray(image.numpy())\n",
        "\n",
        "  # function to be applied to each element in a dataset\n",
        "  def convert_to_gray(image, label):    # note each element is comprised of an image and a label\n",
        "    return tf.reduce_mean(image, axis=-1), label\n",
        "\n",
        "  def train_step(self, real_images):\n",
        "    if isinstance(real_images, tuple):\n",
        "      real_images = real_images[0]\n",
        "    # Sample random points in the latent space\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.incoming_shape))\n",
        "\n",
        "    # Decode them to fake images\n",
        "    generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "    # Combine them with real images\n",
        "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "    # Assemble labels discriminating real from fake images\n",
        "    labels = tf.concat(\n",
        "        [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "    )\n",
        "    # Add random noise to the labels - important trick!\n",
        "    # discussed here: https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\n",
        "    labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "    # Train the discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.discriminator(combined_images)\n",
        "      d_loss = self.loss_fn(labels, predictions)\n",
        "    grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "    self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "    #f = tf.where(predictions > 0.5, 1, 0)\n",
        "    #y = tf.where(labels > 0.5, 1, 0)\n",
        "    #hits = tf.equal(y, f)\n",
        "    #d_acc = tf.reduce_mean( tf.cast(hits, dtype=tf.float32) )\n",
        "\n",
        "    # Sample random points in the latent space\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.incoming_shape))\n",
        "\n",
        "    # Assemble labels that say \"all real images\"\n",
        "    misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "    # Train the generator (note that we should *not* update the weights\n",
        "    # of the discriminator)!\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "      g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "    self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "    if None != self.Checkpoint:\n",
        "      self.Checkpoint.save(file_prefix=self.CheckpointPrefix)\n",
        "\n",
        "    return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gNQUIKYtURs"
      },
      "source": [
        "class StageIGANMonitor(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, num_img=3, incoming_shape=128, image_dir=\"\", name=\"\"):\n",
        "    self.num_img = num_img\n",
        "    self.incoming_shape = incoming_shape\n",
        "    self.image_dir = image_dir\n",
        "    self.name=name\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    random_latent_vectors = tf.random.normal(shape=(self.num_img, self.incoming_shape))\n",
        "    generated_images = self.model.generator(random_latent_vectors)\n",
        "    generated_images *= 255\n",
        "    generated_images.numpy()\n",
        "    if 0 == epoch%5:\n",
        "      self.model.SaveWeights()\n",
        "    if 0 == epoch%25:\n",
        "      for i in range(self.num_img):\n",
        "        img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "        img.save(self.image_dir+\"/genimg_%s_%03d_%d.png\" % (self.name,epoch, i))\n",
        "\n",
        "class StageIIGANMonitor(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, num_img=3, incoming_shape=128, image_dir=\"\", name=\"\"):\n",
        "    self.num_img = num_img\n",
        "    self.incoming_shape = incoming_shape\n",
        "    self.image_dir = image_dir\n",
        "    self.name=name\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    random_latent_vectors = tf.random.normal(shape=(self.num_img, self.model.PrevStage.incoming_shape))\n",
        "    low_res_images = self.model.PrevStage(random_latent_vectors)\n",
        "    generated_images = self.model.generator(low_res_images)\n",
        "    generated_images *= 255\n",
        "    generated_images.numpy()\n",
        "    if 0 == epoch%5:\n",
        "      self.model.SaveWeights()\n",
        "    if 0 == epoch%25:\n",
        "      for i in range(self.num_img):\n",
        "        img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "        img.save(self.image_dir+\"/genimg_%s_%03d_%d.png\" % (self.name,epoch, i))\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgx8PnSPNQsM"
      },
      "source": [
        "import tensorflow as tf\n",
        "class StackGANStage(GAN):\n",
        "  def __init__ (self, desc, trainingClass, \n",
        "                batch_size, incoming_shape, outgoing_shape):\n",
        "    self.batch_size = batch_size\n",
        "    self.validation_split=0.97\n",
        "    self.seed=5549\n",
        "    self.train_ds=None\n",
        "    self.test_ds=None\n",
        "    self.normalized_train_ds=None\n",
        "    # finish construction of a basic GAN\n",
        "    super(StackGANStage, self).__init__(\n",
        "      desc = desc,\n",
        "      incoming_shape=incoming_shape,\n",
        "      outgoing_shape=outgoing_shape,\n",
        "      trainingClass=trainingClass)\n",
        "        \n",
        "  def PrepTrainingData(self, landscape_data_dir, preproc=None):\n",
        "    image_count = len(list(landscape_data_dir.glob('*/*.jpg')))\n",
        "    landscape_photos = list(landscape_data_dir.glob('photos/*.jpg'))\n",
        "\n",
        "    if (image_count < (self.batch_size*5)):\n",
        "      self.batch_size = int(image_count/5)\n",
        "\n",
        "    self.train_ds=None\n",
        "    self.test_ds=None\n",
        "    if (0 < self.validation_split):\n",
        "      self.train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        landscape_data_dir,\n",
        "        validation_split=self.validation_split,\n",
        "        subset=\"training\",\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        seed=self.seed,\n",
        "        image_size=(self.outgoing_shape[0], self.outgoing_shape[1]),\n",
        "        batch_size=self.batch_size)\n",
        "      class_names = self.train_ds.class_names\n",
        "      #print(class_names)\n",
        "\n",
        "      self.test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        landscape_data_dir,\n",
        "        validation_split=self.validation_split,\n",
        "        subset=\"validation\",\n",
        "        color_mode='rgb',\n",
        "        seed=self.seed,\n",
        "        image_size=(self.outgoing_shape[0], self.outgoing_shape[1]),\n",
        "        batch_size=self.batch_size)\n",
        "    else:\n",
        "      self.train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        landscape_data_dir,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        seed=self.seed,\n",
        "        image_size=(self.outgoing_shape[0], self.outgoing_shape[1]),\n",
        "        batch_size=self.batch_size)\n",
        "      class_names = self.train_ds.class_names  \n",
        "    \n",
        "    if (None != preproc):\n",
        "      # normalize the already shuffled training data\n",
        "      self.normalized_train_ds = self.train_ds.map(lambda x, y: (preproc(x), y))\n",
        "    else:\n",
        "      #Just point the normailzzed_train_ds to train_ds\n",
        "      self.normalized_train_ds = self.train_ds\n",
        "\n",
        "  def DisplaySamples(self):\n",
        "    class_names = self.train_ds.class_names\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    for images, labels in self.train_ds.take(1):\n",
        "      for i in range(4):\n",
        "        ax = plt.subplot(2, 2, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "  \n",
        "  def LrScheduler(self, epoch, lr):\n",
        "    stepBreak=50\n",
        "    if (epoch >= stepBreak) and (0==(epoch%stepBreak)):\n",
        "      return lr * 0.5\n",
        "    else:\n",
        "      return lr\n",
        "\n",
        "  def Compile(self):\n",
        "    super(StackGANStage, self).Compile(\n",
        "      d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "      g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "      loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
        "    \n",
        "  def Train(self,epochs=600, name=\"\"):\n",
        "    self.trainable = True\n",
        "    self.generator.trainable = True\n",
        "    self.discriminator.trainable = True\n",
        " \n",
        "    self.fit(self.normalized_train_ds, epochs=epochs\n",
        "               ,callbacks=[StageIGANMonitor(num_img=2, incoming_shape=self.incoming_shape, image_dir=self.GeneratedImageDir, name=name),\n",
        "                          tf.keras.callbacks.LearningRateScheduler(self.LrScheduler)\n",
        "                          ]\n",
        "              )\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeoKf4RdC79i"
      },
      "source": [
        "\n",
        "def GetUpSample(x, filters, kernel_size, strides, upsample_size, label):\n",
        "  ux1=tf.keras.layers.UpSampling2D(size=upsample_size , data_format=None, interpolation='nearest')(x)\n",
        "  ux2=tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, name=label, padding=\"same\", strides=strides, use_bias=False)(ux1)\n",
        "  ux3=tf.keras.layers.BatchNormalization()(ux2)\n",
        "  return tf.keras.layers.ReLU()(ux3)\n",
        "\n",
        "def GetStageIDownSample(x, filters, kernel_size, strides, label, useActivation):\n",
        "  dx1 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, name=label, padding=\"same\", strides=strides, use_bias=False)(x)\n",
        "  dx2 = tf.keras.layers.BatchNormalization()(dx1)\n",
        "  if (useActivation):\n",
        "    dx3 = tf.keras.layers.LeakyReLU(alpha=0.2)(dx2)\n",
        "    return dx3\n",
        "  else:\n",
        "    return dx2\n",
        "\n",
        "def GetStageIIResidual(x, kernel_size, label1, label2):\n",
        "  y = tf.keras.layers.Conv2D(filters=448, kernel_size=kernel_size, name=label1, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "  x = tf.keras.layers.BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(y)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  x = tf.keras.layers.Conv2D(filters=448, kernel_size=kernel_size, name=label2, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "  x = tf.keras.layers.BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "  residualLayer = tf.keras.layers.Add()([x, y])\n",
        "  return tf.keras.layers.ReLU()(residualLayer)\n",
        "\n",
        "def GetStageIIDownSample(x, filters, kernel_size, strides, label, normalize):\n",
        "  #x = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(x)\n",
        "  x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, name=label, padding=\"same\", strides=strides, use_bias=False)(x)\n",
        "  if (normalize):\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "  return tf.keras.layers.LeakyReLU(alpha=0.2)(x)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6AzG5va5PS9"
      },
      "source": [
        "class StackGANStageI(StackGANStage):\n",
        "  def __init__ (self, desc, trainingClass, batch_size, incoming_shape, outgoing_shape):    \n",
        "    # finish construction of a StackGAN\n",
        "    super(StackGANStageI, self).__init__(\n",
        "      desc, trainingClass, \n",
        "      batch_size, incoming_shape, outgoing_shape)\n",
        "\n",
        "  def GetGenerator(self):\n",
        "    i = tf.keras.Input(shape=(self.incoming_shape))\n",
        "    x = tf.keras.layers.Flatten()(i)\n",
        "    x = tf.keras.layers.Dense(int(self.outgoing_shape[0]/16) * int(self.outgoing_shape[0]/16) * 128 * 8)(x)\n",
        "    x = tf.keras.layers.Reshape(\n",
        "            (int(self.outgoing_shape[0]/16), int(self.outgoing_shape[0]/16), 128 * 8),\n",
        "            input_shape=(int(self.outgoing_shape[0]/16) * int(self.outgoing_shape[0]/16) * 128 * 8,))(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = GetUpSample(x, filters=512, kernel_size=(3,3), strides=1, upsample_size=(2,2),  label=str(self.desc)+\"_GConv-U1\" )\n",
        "    x = GetUpSample(x, filters=256, kernel_size=(3,3), strides=1, upsample_size=(2,2), label=str(self.desc)+\"_GConv-U224\" )\n",
        "    x = GetUpSample(x, filters=128, kernel_size=(3,3), strides=1, upsample_size=(2,2), label=str(self.desc)+\"_GConv-U112\" )\n",
        "    x = GetUpSample(x, filters=64, kernel_size=(3,3), strides=1, upsample_size=(2,2), label=str(self.desc)+\"_GConv-U56\" )\n",
        "    x = tf.keras.layers.Conv2D(filters=self.outgoing_shape[2], kernel_size=(3,3), name=str(self.desc)+\"_GConv-Final\", padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    o = tf.keras.layers.Activation(tf.nn.tanh)(x)\n",
        "    model = tf.keras.Model(name=self.desc+\"_Generator\", inputs=i, outputs=o)\n",
        "    #model.summary()\n",
        "    assert model.output_shape ==  (None, 64, 64, 3)\n",
        "    return model\n",
        "\n",
        "  def GetDiscriminator(self):\n",
        "    i = tf.keras.Input(shape=self.outgoing_shape)\n",
        "    x = tf.keras.layers.Conv2D(filters=self.outgoing_shape[0], kernel_size=int(self.outgoing_shape[0]/16), name=str(self.desc)+\"_DConv-1\", padding=\"same\", strides=2, use_bias=False)(i)\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)  \n",
        "    x = GetStageIDownSample(x, filters=2*self.outgoing_shape[0], kernel_size=int(self.outgoing_shape[0]/16), strides=1, label=str(self.desc)+\"_DConv-2\", useActivation=True )\n",
        "    x = GetStageIDownSample(x, filters=4*self.outgoing_shape[0], kernel_size=int(self.outgoing_shape[0]/16), strides=1, label=str(self.desc)+\"_DConv-3\", useActivation=True )\n",
        "    x = GetStageIDownSample(x, filters=8*self.outgoing_shape[0], kernel_size=int(self.outgoing_shape[0]/16), strides=1, label=str(self.desc)+\"_DConv-4\", useActivation=True )\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    o = tf.keras.layers.Dense(1)(x)\n",
        "    model = tf.keras.Model(name=self.desc+\"_Discriminator\", inputs=i, outputs=o)\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf7RjaahSSKO"
      },
      "source": [
        "class StackGANStageII(StackGANStage):\n",
        "  def __init__ (self, desc, trainingClass, batch_size, prevStage, outgoing_shape):\n",
        "    # finish construction of a StackGAN\n",
        "    super(StackGANStageII, self).__init__(\n",
        "      desc, trainingClass,\n",
        "      batch_size, prevStage.outgoing_shape, outgoing_shape)\n",
        "    self.PrevStage = prevStage\n",
        "    \n",
        "  def GetGenerator(self):\n",
        "    i = tf.keras.Input(shape=self.incoming_shape)\n",
        "\n",
        "\n",
        "    #i = tf.keras.applications.VGG19(input_shape=self.incoming_shape,  weights='imagenet', include_top=False)\n",
        "    #i.trainable = False  # mark all weights as non-trainable\n",
        "    #for layer in i.layers:\n",
        "    #  layer.trainable = False\n",
        "  \n",
        "    x = tf.keras.layers.Conv2D(filters=112, kernel_size=(5,5), name=str(self.desc)+\"_GConv-Reshape1\", strides=1, use_bias=False)(i)\n",
        "    x = tf.keras.layers.Conv2D(filters=112, kernel_size=(5,5), name=str(self.desc)+\"_GConv-Reshape2\", strides=1, use_bias=False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "    #DownSample\n",
        "    x = GetStageIIDownSample(x,filters=112, kernel_size=(3,3), strides=1, label=str(self.desc)+\"_DConv-D1\", normalize=False )\n",
        "    x = GetStageIIDownSample(x,filters=224, kernel_size=(4,4), strides=2, label=str(self.desc)+\"_DConv-D2\", normalize=True )\n",
        "    x = GetStageIIDownSample(x,filters=448, kernel_size=(4,4), strides=2, label=str(self.desc)+\"_DConv-D3\", normalize=True )\n",
        "\n",
        "    #Residual Block\n",
        "    x = GetStageIIResidual(x,kernel_size=(3,3), label1=str(self.desc)+\"_GConv-R1\", label2=str(self.desc)+\"_GConv-R2\")\n",
        "    x = GetStageIIResidual(x,kernel_size=(3,3), label1=str(self.desc)+\"_GConv-R3\", label2=str(self.desc)+\"_GConv-R4\")\n",
        "    x = GetStageIIResidual(x,kernel_size=(3,3), label1=str(self.desc)+\"_GConv-R5\", label2=str(self.desc)+\"_GConv-R6\")\n",
        "    x = GetStageIIResidual(x,kernel_size=(3,3), label1=str(self.desc)+\"_GConv-R7\", label2=str(self.desc)+\"_GConv-R8\")\n",
        "\n",
        "    #UpSample\n",
        "    x = GetUpSample(x,filters=448, kernel_size=(3,3), strides=1, upsample_size=(2,2), label=str(self.desc)+\"_GConv-U1\" )\n",
        "    x = GetUpSample(x,filters=224, kernel_size=(3,3), strides=1, upsample_size=(2,2), label=str(self.desc)+\"_GConv-U2\" )\n",
        "    x = GetUpSample(x,filters=112, kernel_size=(3,3), strides=1, upsample_size=(2,2), label=str(self.desc)+\"_GConv-U3\" )\n",
        "    x = GetUpSample(x,filters=56,  kernel_size=(3,3), strides=1, upsample_size=(2,2), label=str(self.desc)+\"_GConv-U4\" )\n",
        "        \n",
        "    #UpSample and output\n",
        "    x = tf.keras.layers.Conv2D(filters=self.outgoing_shape[2], kernel_size=(3,3), name=str(self.desc)+\"_GConv-U5\", padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    o = tf.keras.layers.Activation(tf.nn.tanh)(x)\n",
        "    model = tf.keras.Model(name=self.desc+\"_Generator\", inputs=i, outputs=o)\n",
        "    #model.summary()\n",
        "    assert model.output_shape == (None, 224, 224, 3)\n",
        "    return model\n",
        "  \n",
        "  def GetDiscriminator(self):\n",
        "    #i = tf.keras.Input(shape=self.outgoing_shape)\n",
        "\n",
        "    if ((None, 224,224,3) == self.outgoing_shape  or (224,224,3) == self.outgoing_shape):\n",
        "      backbone = tf.keras.applications.MobileNetV2(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "    else:\n",
        "      backbone = tf.keras.applications.MobileNetV2(input_shape=self.outgoing_shape,  weights='imagenet', include_top=False)\n",
        "    #backbone = tf.keras.applications.MobileNetV2(input_shape=self.outgoing_shape, weights='imagenet', include_top=False)\n",
        "    backbone.trainable = False  # mark all weights as non-trainable\n",
        "    for layer in backbone.layers:\n",
        "      layer.trainable = False\n",
        "    x = backbone.output\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(4,4), name=str(self.desc)+\"_DConv-1\", padding=\"same\", strides=2, use_bias=False)(x)\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = GetStageIDownSample(x,filters=128, kernel_size=(3,3), strides=2, label=str(self.desc)+\"_DConv-2\", useActivation=True )\n",
        "    x = GetStageIDownSample(x,filters=256, kernel_size=(4,4), strides=2, label=str(self.desc)+\"_DConv-3\", useActivation=True )\n",
        "    x = GetStageIDownSample(x,filters=512, kernel_size=(4,4), strides=2, label=str(self.desc)+\"_DConv-4\", useActivation=True )\n",
        "    x = GetStageIDownSample(x,filters=1024, kernel_size=(4,4), strides=2, label=str(self.desc)+\"_DConv-5\", useActivation=True )\n",
        "    x = GetStageIDownSample(x,filters=2048, kernel_size=(4,4), strides=2, label=str(self.desc)+\"_DConv-6\", useActivation=True )\n",
        "    x = GetStageIDownSample(x,filters=1024, kernel_size=(1,1), strides=1, label=str(self.desc)+\"_DConv-7\", useActivation=True )\n",
        "    x = GetStageIDownSample(x,filters=512, kernel_size=(1,1), strides=1, label=str(self.desc)+\"_DConv-8\", useActivation=False )\n",
        "       \n",
        "    y = GetStageIDownSample(x,filters=128, kernel_size=(1,1), strides=1, label=str(self.desc)+\"_DConv-9\", useActivation=True )\n",
        "    y = GetStageIDownSample(y,filters=128, kernel_size=(3,3), strides=1, label=str(self.desc)+\"_DConv-10\", useActivation=True )\n",
        "    y = GetStageIDownSample(y,filters=512, kernel_size=(3,3), strides=1, label=str(self.desc)+\"_DConv-11\", useActivation=False )\n",
        "\n",
        "    residualLayer = tf.keras.layers.Add()([x, y])  \n",
        "    z = tf.keras.layers.LeakyReLU(alpha=0.2)(residualLayer)\n",
        "\n",
        "    #Output\n",
        "    z = tf.keras.layers.Flatten()(z)\n",
        "    o = tf.keras.layers.Dense(1)(z)\n",
        "    model = tf.keras.Model(name=self.desc+\"_Discriminator\", inputs=backbone.input, outputs=o)\n",
        "    #model.summary()\n",
        "    return model\n",
        "\n",
        "  def Train(self,epochs=600, name=\"\"):\n",
        "    self.PrevStage.trainable = False\n",
        "    self.PrevStage.generator.trainable =False\n",
        "    self.PrevStage.discriminator.trainable =False\n",
        "    self.fit(self.normalized_train_ds, epochs=epochs\n",
        "               ,callbacks=[StageIIGANMonitor(num_img=2, incoming_shape=self.incoming_shape, image_dir=self.GeneratedImageDir, name=name),\n",
        "                          tf.keras.callbacks.LearningRateScheduler(self.LrScheduler)\n",
        "                          ]\n",
        "              )\n",
        "  \n",
        "  def ProcessGeneratorOutput(self, gendata):\n",
        "    data = tf.math.multiply(gendata,255.0)\n",
        "    out = tf.keras.applications.mobilenet_v2.preprocess_input(data)\n",
        "    return out\n",
        "\n",
        "  def GetPrevStageOutput(self, random_latent_vectors):\n",
        "    g = self.PrevStage\n",
        "    low_res_images=g(random_latent_vectors)\n",
        "    return low_res_images\n",
        "\n",
        "  def train_step(self, real_images):\n",
        "    if isinstance(real_images, tuple):\n",
        "      real_images = real_images[0]\n",
        "    # Sample random points in the latent space\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.PrevStage.incoming_shape))\n",
        "\n",
        "    #Generate lower-res fake images from PrevStage\n",
        "    low_res_images=self.GetPrevStageOutput(random_latent_vectors)\n",
        "    tf.print(low_res_images)\n",
        "\n",
        "    # Decode them to high-res fake images\n",
        "    generated_images = self.generator(low_res_images)\n",
        "    #Generate lower-res fake images from PrevStage\n",
        "    generated_images = self.ProcessGeneratorOutput(generated_images)\n",
        "\n",
        "    # Combine them with real images\n",
        "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "    # Assemble labels discriminating real from fake images\n",
        "    labels = tf.concat(\n",
        "        [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "    )\n",
        "    # Add random noise to the labels - important trick!\n",
        "    # discussed here: https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\n",
        "    labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "    # Train the discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.discriminator(combined_images)\n",
        "      d_loss = self.loss_fn(labels, predictions)\n",
        "    grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "    self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "    #f = tf.where(predictions > 0.5, 1, 0)\n",
        "    #y = tf.where(labels > 0.5, 1, 0)\n",
        "    #hits = tf.equal(y, f)\n",
        "    #d_acc = tf.reduce_mean( tf.cast(hits, dtype=tf.float32) )\n",
        "\n",
        "    # Sample random points in the latent space\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.PrevStage.incoming_shape))\n",
        "\n",
        "    #Generate lower-res fake images from PrevStage\n",
        "    low_res_images=self.GetPrevStageOutput(random_latent_vectors)\n",
        "\n",
        "    # Assemble labels that say \"all real images\"\n",
        "    misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "    # Train the generator (note that we should *not* update the weights\n",
        "    # of the discriminator)!\n",
        "    with tf.GradientTape() as tape:\n",
        "      generated_images = self.generator(low_res_images)\n",
        "      generated_images = self.ProcessGeneratorOutput(generated_images)\n",
        "      predictions = self.discriminator(generated_images)\n",
        "      g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "    self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "    if None != self.Checkpoint:\n",
        "      self.Checkpoint.save(file_prefix=self.CheckpointPrefix)\n",
        "\n",
        "    return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCYGpfA8tv6f"
      },
      "source": [
        "class GANDinsky(object):\n",
        "  def __init__(self, trainingClass, useSampleData, prepForTraining=False, projectDir=None):\n",
        "    # Prep GANdisky specific data members\n",
        "    self.TrainingParam={\n",
        "        \"batch_size\":64,\n",
        "        \"stageIOutputHeight\":64,\n",
        "        \"stageIOutputWidth\":64,\n",
        "        \"stageIOutputDepth\":3,\n",
        "        \"stageIIOutputHeight\":224,\n",
        "        \"stageIIOutputWidth\":224,\n",
        "        \"stageIIOutputDepth\":3,\n",
        "      }\n",
        "    incoming_shape = 128\n",
        "    \n",
        "    self.UseSampleData = useSampleData\n",
        "    self.ProjectDir=projectDir\n",
        "    if None == self.ProjectDir:\n",
        "      self.ProjectDir=\"/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/\"\n",
        "      if True == self.UseSampleData:\n",
        "        # If using sample data, overwrite the parameters\n",
        "        self.ProjectDir=\"/content/ChernobylBlueChillers/\"\n",
        "\n",
        "    self.SampleUrl=\"https://drive.google.com/uc?export=download&id=1ZPY_-CFnrCiDucbM0kmQB0G6rgOjoXBs\"\n",
        "    self.SampleDir=self.ProjectDir\n",
        "    self.SampleBundle=self.SampleDir + 'SampleData.zip'\n",
        "\n",
        "    #photo directory information\n",
        "    self.ProjectLandscapePhotoDir=self.ProjectDir + \"landscape/photos/\"\n",
        "    self.ProjectLandscapeDir=self.ProjectDir + \"landscape/\"\n",
        "    #https://www.kaggle.com/arnaud58/landscape-pictures\n",
        "    self.PhotoBundleUrl=\"https://www.dropbox.com/s/y32o3a53eij6a0w/landscape_photos.zip?dl=1\"\n",
        "    self.PhotoBundle=self.ProjectLandscapePhotoDir + 'kaggle-landscape_photos.zip'\n",
        "\n",
        "    self.StageI=StackGANStageI(\"LandScape_StageI\", trainingClass, self.TrainingParam[\"batch_size\"], \n",
        "                               incoming_shape,\n",
        "                               outgoing_shape=(self.TrainingParam[\"stageIOutputHeight\"], \n",
        "                                self.TrainingParam[\"stageIOutputWidth\"], \n",
        "                                self.TrainingParam[\"stageIOutputDepth\"]))\n",
        "    self.StageI.ModelDir = self.ProjectDir + trainingClass +\"/model\" +  \"/StageI/\"\n",
        "    self.StageI.GeneratedImageDir=self.ProjectDir + trainingClass +\"/generatedImages\" +  \"/StageI/\"\n",
        "    self.StageI.LoadWeights()\n",
        "    self.StageII=StackGANStageII(\"LandScape_StageII\", trainingClass, self.TrainingParam[\"batch_size\"], \n",
        "                                self.StageI, \n",
        "                                outgoing_shape=(self.TrainingParam[\"stageIIOutputHeight\"], \n",
        "                                  self.TrainingParam[\"stageIIOutputWidth\"], \n",
        "                                  self.TrainingParam[\"stageIIOutputDepth\"]))\n",
        "    self.StageII.ModelDir = self.ProjectDir + trainingClass + \"/model\" + \"/StageII/\"\n",
        "    self.StageII.GeneratedImageDir=self.ProjectDir + trainingClass + \"/generatedImages\" + \"/StageII/\"\n",
        "    self.StageII.LoadWeights()\n",
        "\n",
        "    prep_drive(not self.UseSampleData, [self.StageI.ModelDir, self.StageII.ModelDir])\n",
        "    os.chdir(self.ProjectDir)\n",
        "\n",
        "    if True == prepForTraining:\n",
        "      self.PrepForTraining()\n",
        "\n",
        "  def __call__(self, inputs, training=None, mask=None):\n",
        "    SI = self.StageI(inputs,training,mask)\n",
        "    return self.StageII(SI, training, mask)\n",
        "    \n",
        "  def PrepForTraining(self):\n",
        "    prep_drive(not self.UseSampleData, \n",
        "                [self.ProjectDir, self.ProjectLandscapePhotoDir, \n",
        "                self.StageI.GeneratedImageDir,self.StageII.GeneratedImageDir])\n",
        "    os.chdir(self.ProjectDir)\n",
        "    self.DownloadAndExtractData()\n",
        "\n",
        "    rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "    preproc = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "    self.StageI.PrepTrainingData(pathlib.Path(self.ProjectLandscapeDir), rescale)\n",
        "    self.StageII.PrepTrainingData(pathlib.Path(self.ProjectLandscapeDir), preproc)\n",
        "    self.Compile()\n",
        "\n",
        "  def DownloadAndExtractData(self):\n",
        "    if self.UseSampleData:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the sample Data\n",
        "      download_and_extract_file(self.SampleUrl, self.SampleBundle, self.SampleDir)\n",
        "    else:\n",
        "      ########################################################################################\n",
        "      # 1. Download and Extract the image library\n",
        "      download_and_extract_file(self.PhotoBundleUrl, self.PhotoBundle, self.ProjectLandscapePhotoDir)\n",
        "\n",
        "  def get_config(self):\n",
        "    retVal = super(GANDinsky, self).get_config()\n",
        "    retVal[\"TrainingParam\"]=self.TrainingParam\n",
        "    retVal[\"UseSampleData\"]=self.UseSampleData\n",
        "    retVal[\"SampleUrl\"]=self.SampleUrl\n",
        "    retVal[\"SampleDir\"]=self.SampleDir\n",
        "    retVal[\"SampleBundle\"]=self.SampleBundle\n",
        "    retVal[\"ProjectLandscapePhotoDir\"]=self.ProjectLandscapePhotoDir\n",
        "    retVal[\"ProjectLandscapeDir\"]=self.ProjectLandscapeDir\n",
        "    retVal[\"PhotoBundleUrl\"]=self.PhotoBundleUrl\n",
        "    retVal[\"PhotoBundle\"]=self.PhotoBundle\n",
        "    retVal[\"StageI\"]=self.StageI\n",
        "    retVal[\"StageII\"]=self.StageII\n",
        "    return retVal\n",
        "\n",
        "  def DisplaySamples(self):\n",
        "    self.StageI.DisplaySamples()\n",
        "    #self.StageII.DisplaySamples()\n",
        "\n",
        "  def LoadWeights(self):\n",
        "    self.StageI.LoadWeights()\n",
        "    self.StageII.LoadWeights()\n",
        "\n",
        "  def SaveWeights(self):\n",
        "    self.StageI.SaveWeights()\n",
        "    self.StageII.SaveWeights()\n",
        "\n",
        "  def Compile(self):\n",
        "    self.StageI.Compile()\n",
        "    self.StageII.Compile()\n",
        "  \n",
        "  def Summary(self):\n",
        "    self.StageI.Summary()\n",
        "    self.StageII.Summary()\n",
        "\n",
        "  def Train(self,epochs=100, name=\"\"):\n",
        "    self.StageI.Train(epochs=epochs, name=name)\n",
        "    self.StageII.Train(epochs=epochs, name=name)\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRQJzl1D3hK4"
      },
      "source": [
        "gan = GANDinsky(trainingClass=\"lp56v2\", useSampleData=False, prepForTraining=True)\n",
        "gan.DisplaySamples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmAJFBYwLu2B"
      },
      "source": [
        "#iterations=1\n",
        "#initialIteration=1\n",
        "#epochs=1\n",
        "#stage=gan.StageII\n",
        "#for i in range(initialIteration,initialIteration+iterations):\n",
        "#  stage.Train(epochs, stage.TrainingClass + str(i))\n",
        "#  #stage.SaveWeights()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PvonkRxwWki"
      },
      "source": [
        "image=gan.StageI.generator(dna.SampleDNAData[dna.DNAData[1]])[0]\n",
        "\n",
        "#generated_images = gan(dna.SampleDNAData[dna.DNAData[1]])\n",
        "#image=generated_images[0]\n",
        "#print(image)\n",
        "\n",
        "gan.StageI.DisplayImageArray(image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}