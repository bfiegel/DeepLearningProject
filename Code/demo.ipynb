{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISE 6380: Chernobyl Blue Chillers - GANdinsky.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHE8cdQMTO1U",
        "outputId": "d387b3ea-3816-4f39-e5be-7bbae056ef8a"
      },
      "source": [
        "!pip install biopython\n",
        "\n",
        "import Bio\n",
        "from google.colab import drive\n",
        "import numpy as np \n",
        "import os\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "useSampleData=True\n",
        "\n",
        "project_dir=\"/content/drive/MyDrive/UIowa/ISE/ISE6380/ChernobylBlueChillers/GANdinsky/\"\n",
        "if True == useSampleData:\n",
        "  # If using sample data, overwrite the parameters\n",
        "  project_dir=\"/content/ChernobylBlueChillers/\"\n",
        "sample_url=\"https://drive.google.com/uc?export=download&id=1ZPY_-CFnrCiDucbM0kmQB0G6rgOjoXBs\"\n",
        "sample_dir=project_dir\n",
        "sample_bundle=sample_dir + 'SampleData.zip'\n",
        "\n",
        "#photo directory information\n",
        "project_landscape_photo_dir=project_dir + \"landscape/photos/\"\n",
        "project_landscape_dir=project_dir + \"landscape/\"\n",
        "#https://www.kaggle.com/arnaud58/landscape-pictures\n",
        "photo_bundle_url=\"https://storage.googleapis.com/kaggle-data-sets/298806/1217826/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210228%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210228T202950Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=16593e15698fc6080632d46623d25f3a5e2181fe3d6a94eb70f27dba657ded3b4d1b73c850b64a96fa294d7ca2404794577386743f72f452c50d49073411729bcf16404c1695fffb9a6e9aff075cfa54906ac9b96352d4fb28f546a1f57a52b97b205541aaa7f60325e4d9a7e7054ec0d099b760cab8110f6517ec401c9c810bbee66a4bc2566e745da43d3c7d4957e10301d72bd086169789a0c184d90f1e5f68b96d8c16707c125ee5e83035a016bdf736b7a347384e88392395615d5cadd1274c535e956cdf00e27c4d78d07160b861886760f5d84e2e689470dd761976788671f6b08caf86a15fb3f87c79f39a66bf6eba6a02b8150daabe1297d6e5a2fc\"\n",
        "photo_bundle=project_landscape_photo_dir + 'kaggle-landscape_photos.zip'\n",
        "\n",
        "project_dna_dir=project_dir + \"DNAData/\"\n",
        "#Bsubtilis_JRC DNA data\n",
        "Bsubtilis_JRC_bundle_url=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-JRC.tgz\"\n",
        "Bsubtilis_JRC_bundle = project_dna_dir + 'Bsubtilis-JRC.tgz'\n",
        "project_dna_Bsubtilis_JRC_dir=project_dna_dir + \"Bsubtilis-JRC/\"\n",
        "project_dna_Bsubtilis_JRC_data = [project_dna_Bsubtilis_JRC_dir + \"Bsubtilis-JRC.fastq\"]\n",
        "\n",
        "#Bsubtilis_LGL DNA data\n",
        "Bsubtilis_LGL_bundle_url=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-LGL.tgz\"\n",
        "Bsubtilis_LGL_bundle = project_dna_dir + 'Bsubtilis-LGL.tgz'\n",
        "project_dna_Bsubtilis_LGL_dir=project_dna_dir + \"Bsubtilis-LGL/\"\n",
        "project_dna_Bsubtilis_LGL_data = []#[project_dna_Bsubtilis_LGL_dir + \"Bsubtilis-LGL.fastq\"]\n",
        "\n",
        "#Bsubtilis_LHL DNA data\n",
        "Bsubtilis_LHL_bundle_url=\"http://cidportal.jrc.ec.europa.eu/ftp/jrc-opendata/BIOINFORMATICS/Bacillus-subtilis/VER1-0/Bsubtilis-LHL.tgz\"\n",
        "Bsubtilis_LHL_bundle = project_dna_dir + 'Bsubtilis-LHL.tgz'\n",
        "project_dna_Bsubtilis_LHL_dir=project_dna_dir + \"Bsubtilis-LHL/\"\n",
        "project_dna_Bsubtilis_LHL_data = [project_dna_Bsubtilis_LHL_dir + \"Bsubtilis_S1_L001_R1_001.fastq\"]\n",
        "\n",
        "if True == useSampleData:\n",
        "  # If using sample data, overwrite the parameters\n",
        "  project_dna_Bsubtilis_JRC_data = [project_dna_Bsubtilis_JRC_dir + \"Bsubtilis-JRC-truncated.fastq\"]\n",
        "  project_dna_Bsubtilis_LHL_data = [project_dna_Bsubtilis_LHL_dir + \"Bsubtilis_S1_L001_R1_001-truncated.fastq\"]\n",
        "\n",
        "DNAData=[]\n",
        "DNAData.extend(project_dna_Bsubtilis_JRC_data)\n",
        "DNAData.extend(project_dna_Bsubtilis_LGL_data)\n",
        "DNAData.extend(project_dna_Bsubtilis_LHL_data)\n",
        "DNADataRecords={}\n",
        "\n",
        "def prep_drive(doMount):\n",
        "  #mount google drive for longterm storage\n",
        "  if True == doMount:\n",
        "    drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "  if not os.path.isdir(project_dir):\n",
        "    os.makedirs(project_dir)\n",
        "  os.chdir(project_dir)\n",
        "\n",
        "  # prep the photo dir\n",
        "  if not os.path.isdir(project_photo_dir):\n",
        "    os.makedirs(project_photo_dir)\n",
        "\n",
        "  #prep the DNA dir\n",
        "  if not os.path.isdir(project_dna_dir):\n",
        "    os.makedirs(project_dna_dir)\n",
        "\n",
        "def noop():\n",
        "  return None"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (1.78)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBty6HO5OXqG"
      },
      "source": [
        "prep_drive(not useSampleData)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JwWnBBapug8"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "import tarfile\n",
        "import urllib.request\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "def download_and_extract_file(url, local_bundle_path, extraction_directory='.'):\n",
        "  initial_directory = os.getcwd()\n",
        "  os.chdir(extraction_directory)\n",
        "  try:\n",
        "    if not os.path.exists(local_bundle_path):\n",
        "      # download the dataset\n",
        "      urllib.request.urlretrieve(url,local_bundle_path )\n",
        "      \n",
        "      if local_bundle_path.endswith('.zip'):\n",
        "        # extract the dataset and store it on google drive\n",
        "        with ZipFile(local_bundle_path, 'r') as zip:\n",
        "          zip.extractall()\n",
        "      elif local_bundle_path.endswith('.tar.gz') or local_bundle_path.endswith('.tgz'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:gz\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      elif local_bundle_path.endswith('.tar'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      elif path.endswith('.tar.bz2') or path.endswith('.tbz'):\n",
        "        tar = tarfile.open(local_bundle_path, \"r:bz2\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "      else: \n",
        "        raise Exception(local_bundle_path + \" has an unrecognized file extension\")\n",
        "  finally:\n",
        "    os.chdir(initial_directory)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPRTvk-FU4JR"
      },
      "source": [
        "if useSampleData:\n",
        "  ########################################################################################\n",
        "  # 1. Download and Extract the sample Data\n",
        "  download_and_extract_file(sample_url, sample_bundle, sample_dir)\n",
        "else:\n",
        "  ########################################################################################\n",
        "  # 1. Download and Extract the image library\n",
        "  download_and_extract_file(photo_bundle_url, photo_bundle, project_landscape_photo_dir)\n",
        "  ########################################################################################\n",
        "  # 2. Download and Extract the DNA library\n",
        "  download_and_extract_file(Bsubtilis_JRC_bundle_url, Bsubtilis_JRC_bundle, project_dna_dir)\n",
        "  ##This is VERY LARGE, need to figure out if we really want data this large.\n",
        "  ##It caused me to run out of colab disk space.\n",
        "  #download_and_extract_file(Bsubtilis_LGL_bundle_url, Bsubtilis_LGL_bundle, project_dna_dir)\n",
        "  download_and_extract_file(Bsubtilis_LHL_bundle_url, Bsubtilis_LHL_bundle, project_dna_dir)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kaTUh-n1O5d",
        "outputId": "c6336b04-fb7f-4ff9-db78-162293b45dfc"
      },
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "for dataFile in DNAData:\n",
        "  print(dataFile)\n",
        "  DNADataRecords[dataFile]=[] \n",
        "  with open(dataFile, \"r\") as handle:\n",
        "      for record in SeqIO.parse(handle, \"fastq\"):\n",
        "        DNADataRecords[dataFile].append(record)\n",
        "  #      print(record.seq)\n",
        "  #      print(record.id)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ChernobylBlueChillers/DNAData/Bsubtilis-JRC/Bsubtilis-JRC-truncated.fastq\n",
            "/content/ChernobylBlueChillers/DNAData/Bsubtilis-LHL/Bsubtilis_S1_L001_R1_001-truncated.fastq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE80aYTxmuHF",
        "outputId": "8b323e6b-b12e-4c73-d5ef-ed49a258f4d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "landscape_data_dir = pathlib.Path(project_landscape_dir)\n",
        "image_count = len(list(landscape_data_dir.glob('*/*.jpg')))\n",
        "print(image_count)\n",
        "landscape_photos = list(landscape_data_dir.glob('photos/*.jpg'))\n",
        "#PIL.Image.open(str(landscape_photos[0]))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob5N6oCBniVw",
        "outputId": "52850838-7e67-418b-c531-df511283d1f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 32\n",
        "if (image_count < (batch_size*5)):\n",
        "  batch_size= int(image_count/5)\n",
        "print(\"batch_size = \" + str(batch_size))\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "validation_split=0.2\n",
        "seed=5549\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  landscape_data_dir,\n",
        "  validation_split=validation_split,\n",
        "  subset=\"training\",\n",
        "  seed=seed,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  landscape_data_dir,\n",
        "  validation_split=validation_split,\n",
        "  subset=\"validation\",\n",
        "  seed=seed,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_size = 12\n",
            "Found 60 files belonging to 1 classes.\n",
            "Using 48 files for training.\n",
            "Found 60 files belonging to 1 classes.\n",
            "Using 12 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}